[{"path":"https://taf-society.github.io/chronofeat/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2026 chronofeat authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Advanced Workflows","text":"article covers advanced topics production-ready forecasting: Hyperparameter tuning Model comparison frameworks Production deployment patterns Edge cases best practices","code":"library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  data(retail) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"grid-search-with-cv","dir":"Articles","previous_headings":"Hyperparameter Tuning","what":"Grid Search with CV","title":"Advanced Workflows","text":"Systematically search hyperparameter space:","code":"library(xgboost)  # Define parameter grid param_grid <- expand.grid(   nrounds = c(50, 100, 200),   max_depth = c(3, 6, 9),   eta = c(0.01, 0.1, 0.3) )  # XGBoost model specification factory make_xgb_spec <- function(nrounds, max_depth, eta) {   list(     fit = function(y, X, ...) {       X_mat <- model.matrix(~ . - 1, data = X)       xgboost(         data = X_mat, label = y,         nrounds = nrounds,         max_depth = max_depth,         eta = eta,         verbose = 0       )     },     predict = function(object, newdata, ...) {       X_mat <- model.matrix(~ . - 1, data = newdata)       predict(object, X_mat)     }   ) }  # Run grid search results <- lapply(1:nrow(param_grid), function(i) {   params <- param_grid[i, ]    cv <- cv_forecast(     value ~ p(12) + month(),     data = ts_data,     model = make_xgb_spec(params$nrounds, params$max_depth, params$eta),     h = 6,     n_windows = 3   )    data.frame(     nrounds = params$nrounds,     max_depth = params$max_depth,     eta = params$eta,     rmse = cv$metrics[cv$metrics$fold == 0, \"rmse\"]   ) })  grid_results <- do.call(rbind, results) best_params <- grid_results[which.min(grid_results$rmse), ] print(best_params)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"random-search","dir":"Articles","previous_headings":"Hyperparameter Tuning","what":"Random Search","title":"Advanced Workflows","text":"efficient large parameter spaces:","code":"set.seed(42) n_trials <- 20  random_params <- data.frame(   nrounds = sample(50:300, n_trials, replace = TRUE),   max_depth = sample(3:12, n_trials, replace = TRUE),   eta = runif(n_trials, 0.01, 0.3),   subsample = runif(n_trials, 0.6, 1.0),   colsample_bytree = runif(n_trials, 0.6, 1.0) )  # Run random search (similar to grid search above)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"bayesian-optimization-with-parbayesianoptimization","dir":"Articles","previous_headings":"Hyperparameter Tuning","what":"Bayesian Optimization with ParBayesianOptimization","title":"Advanced Workflows","text":"Bayesian optimization efficient grid random search uses past evaluation results intelligently choose next parameters try. ParBayesianOptimization package provides easy--use interface .","code":"# Install if needed install.packages(\"ParBayesianOptimization\")"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"basic-setup","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Basic Setup","title":"Advanced Workflows","text":"key components : Scoring function: Takes parameters, returns score (higher = better, negate RMSE) Parameter bounds: Define search space Initial points: Random evaluations start optimization","code":"library(ParBayesianOptimization) library(xgboost)  # Prepare data once (outside the scoring function for efficiency) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")  # Define the scoring function # ParBayesianOptimization MAXIMIZES, so return negative RMSE scoring_function <- function(max_depth, eta, subsample, colsample_bytree) {    # Create XGBoost model specification with these parameters   xgb_spec <- list(     fit = function(y, X, ...) {       # Convert factors to numeric       X_mat <- model.matrix(~ . - 1, data = X)        xgboost(         data = X_mat,         label = y,         nrounds = 100,  # Fixed for speed; tune separately if needed         max_depth = max_depth,         eta = eta,         subsample = subsample,         colsample_bytree = colsample_bytree,         objective = \"reg:squarederror\",         verbose = 0       )     },     predict = function(object, newdata, ...) {       X_mat <- model.matrix(~ . - 1, data = newdata)       predict(object, X_mat)     }   )    # Run cross-validation   cv_result <- cv_forecast(     value ~ p(12) + month(),     data = ts_data,     model = xgb_spec,     h = 6,     n_windows = 3,     metric = \"rmse\"   )    # Extract overall RMSE  rmse <- cv_result$metrics[cv_result$metrics$fold == 0, \"rmse\"]    # Return negative RMSE (ParBayesianOptimization maximizes)   list(Score = -rmse) }  # Define parameter bounds bounds <- list(   max_depth = c(2L, 10L),   eta = c(0.01, 0.3),   subsample = c(0.5, 1.0),   colsample_bytree = c(0.5, 1.0) )  # Run optimization set.seed(42) opt_result <- bayesOpt(   FUN = scoring_function,   bounds = bounds,   initPoints = 5,   # Initial random evaluations   iters.n = 15,     # Bayesian optimization iterations   iters.k = 1,      # Points to sample per iteration   verbose = 1 )"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"analyzing-results","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Analyzing Results","title":"Advanced Workflows","text":"","code":"# Best parameters found getBestPars(opt_result)  # Full optimization history opt_result$scoreSummary  # Plot optimization progress plot(opt_result)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"complete-xgboost-tuning-example","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Complete XGBoost Tuning Example","title":"Advanced Workflows","text":"’s production-ready example parameters:","code":"library(ParBayesianOptimization) library(xgboost) library(chronofeat) library(dplyr)  # Load and prepare data data(retail) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")  # Comprehensive scoring function xgb_scoring <- function(max_depth, eta, min_child_weight, subsample,                         colsample_bytree, gamma, lambda, alpha) {    xgb_spec <- list(     fit = function(y, X, ...) {       X_mat <- model.matrix(~ . - 1, data = X)        # Use early stopping with internal validation       n <- length(y)       train_idx <- 1:floor(n * 0.8)       val_idx <- (floor(n * 0.8) + 1):n        dtrain <- xgb.DMatrix(data = X_mat[train_idx, ], label = y[train_idx])       dval <- xgb.DMatrix(data = X_mat[val_idx, ], label = y[val_idx])        xgb.train(         params = list(           objective = \"reg:squarederror\",           eval_metric = \"rmse\",           max_depth = max_depth,           eta = eta,           min_child_weight = min_child_weight,           subsample = subsample,           colsample_bytree = colsample_bytree,           gamma = gamma,           lambda = lambda,           alpha = alpha         ),         data = dtrain,         nrounds = 500,         watchlist = list(val = dval),         early_stopping_rounds = 20,         verbose = 0       )     },     predict = function(object, newdata, ...) {       X_mat <- model.matrix(~ . - 1, data = newdata)       predict(object, X_mat)     }   )    cv_result <- cv_forecast(     value ~ p(12) + q(12) + month(),     data = ts_data,     model = xgb_spec,     h = 6,     n_windows = 3,     metric = \"rmse\"   )    rmse <- cv_result$metrics[cv_result$metrics$fold == 0, \"rmse\"]   list(Score = -rmse) }  # Comprehensive parameter bounds bounds <- list(   max_depth = c(2L, 12L),   eta = c(0.01, 0.3),   min_child_weight = c(1L, 10L),   subsample = c(0.5, 1.0),   colsample_bytree = c(0.3, 1.0),   gamma = c(0, 5),   lambda = c(0, 3),    # L2 regularization   alpha = c(0, 3)      # L1 regularization )  # Run optimization with more iterations set.seed(123) opt_result <- bayesOpt(   FUN = xgb_scoring,   bounds = bounds,   initPoints = 10,    # More initial points for higher dimensions   iters.n = 30,       # More iterations   iters.k = 1,   acq = \"ucb\",        # Upper Confidence Bound acquisition function   kappa = 2.576,      # Exploration parameter   verbose = 1 )  # Get best parameters best_params <- getBestPars(opt_result) print(best_params)  # Best score achieved (remember to negate back to RMSE) best_rmse <- -max(opt_result$scoreSummary$Score) cat(\"Best RMSE:\", best_rmse, \"\\n\")"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"tuning-lightgbm-with-parbayesianoptimization","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Tuning LightGBM with ParBayesianOptimization","title":"Advanced Workflows","text":"","code":"library(lightgbm)  lgb_scoring <- function(num_leaves, learning_rate, feature_fraction,                         bagging_fraction, min_data_in_leaf, lambda_l1, lambda_l2) {    lgb_spec <- list(     fit = function(y, X, ...) {       # LightGBM handles categoricals natively       cat_cols <- names(X)[sapply(X, is.factor)]       X_processed <- X       for (col in cat_cols) {         X_processed[[col]] <- as.integer(X[[col]]) - 1L       }        dtrain <- lgb.Dataset(         data = as.matrix(X_processed),         label = y,         categorical_feature = cat_cols       )        lgb.train(         params = list(           objective = \"regression\",           metric = \"rmse\",           num_leaves = num_leaves,           learning_rate = learning_rate,           feature_fraction = feature_fraction,           bagging_fraction = bagging_fraction,           bagging_freq = 1,           min_data_in_leaf = min_data_in_leaf,           lambda_l1 = lambda_l1,           lambda_l2 = lambda_l2,           verbosity = -1         ),         data = dtrain,         nrounds = 200       )     },     predict = function(object, newdata, ...) {       cat_cols <- names(newdata)[sapply(newdata, is.factor)]       X_processed <- newdata       for (col in cat_cols) {         X_processed[[col]] <- as.integer(newdata[[col]]) - 1L       }       predict(object, as.matrix(X_processed))     }   )    cv_result <- cv_forecast(     value ~ p(12) + month(),     data = ts_data,     model = lgb_spec,     h = 6,     n_windows = 3   )    rmse <- cv_result$metrics[cv_result$metrics$fold == 0, \"rmse\"]   list(Score = -rmse) }  bounds_lgb <- list(   num_leaves = c(8L, 128L),   learning_rate = c(0.01, 0.3),   feature_fraction = c(0.5, 1.0),   bagging_fraction = c(0.5, 1.0),   min_data_in_leaf = c(5L, 50L),   lambda_l1 = c(0, 3),   lambda_l2 = c(0, 3) )  opt_lgb <- bayesOpt(   FUN = lgb_scoring,   bounds = bounds_lgb,   initPoints = 8,   iters.n = 20,   verbose = 1 )"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"parallel-bayesian-optimization","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Parallel Bayesian Optimization","title":"Advanced Workflows","text":"faster tuning, use parallel evaluation:","code":"library(doParallel)  # Setup parallel backend cl <- makeCluster(4) registerDoParallel(cl)  # Export required objects to workers clusterExport(cl, c(\"ts_data\", \"cv_forecast\", \"fit\", \"forecast\")) clusterEvalQ(cl, {   library(chronofeat)   library(xgboost)   library(dplyr) })  # Run parallel optimization opt_parallel <- bayesOpt(   FUN = scoring_function,   bounds = bounds,   initPoints = 8,   iters.n = 20,   iters.k = 4,       # Evaluate 4 points in parallel per iteration   parallel = TRUE,   verbose = 1 )  stopCluster(cl)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"tips-for-effective-bayesian-optimization","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Tips for Effective Bayesian Optimization","title":"Advanced Workflows","text":"Start reasonable bounds: wide bounds waste evaluations Use enough initial points: least 2× number parameters Monitor convergence: Plot scores see iterations help Fix parameters: Tune impactful parameters first (eta, max_depth) Use early stopping: Reduces time per evaluation","code":"# Check if optimization has converged scores <- opt_result$scoreSummary$Score plot(scores, type = \"l\", main = \"Optimization Progress\",      xlab = \"Iteration\", ylab = \"Score (negative RMSE)\")  # If scores are still improving, run more iterations opt_result <- addIterations(opt_result, iters.n = 10, verbose = 1)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"using-optimized-parameters","dir":"Articles","previous_headings":"Hyperparameter Tuning > Bayesian Optimization with ParBayesianOptimization","what":"Using Optimized Parameters","title":"Advanced Workflows","text":"finding best parameters, train final model:","code":"# Get best parameters best <- getBestPars(opt_result)  # Create final model specification final_xgb_spec <- list(   fit = function(y, X, ...) {     X_mat <- model.matrix(~ . - 1, data = X)     xgboost(       data = X_mat,       label = y,       nrounds = 200,       max_depth = best$max_depth,       eta = best$eta,       subsample = best$subsample,       colsample_bytree = best$colsample_bytree,       verbose = 0     )   },   predict = function(object, newdata, ...) {     X_mat <- model.matrix(~ . - 1, data = newdata)     predict(object, X_mat)   } )  # Fit final model on all data final_model <- fit(   value ~ p(12) + q(12) + month(),   data = ts_data,   model = final_xgb_spec )  # Generate forecasts forecasts <- forecast(final_model, h = 12)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"structured-comparison","dir":"Articles","previous_headings":"Model Comparison Framework","what":"Structured Comparison","title":"Advanced Workflows","text":"","code":"# Define models to compare models <- list(   lm = list(     spec = lm,     features = \"value ~ p(12) + month()\"   ),   lm_complex = list(     spec = lm,     features = \"value ~ p(12) + q(12) + month() + rollsum(12)\"   ),   rf = list(     spec = randomForest::randomForest,     features = \"value ~ p(12) + month()\"   ),   xgb = list(     spec = make_xgb_spec(100, 6, 0.1),     features = \"value ~ p(12) + month()\"   ) )  # Run comparison comparison <- lapply(names(models), function(name) {   m <- models[[name]]    cv <- cv_forecast(     as.formula(m$features),     data = ts_data,     model = m$spec,     h = 6,     n_windows = 5,     return_predictions = TRUE   )    fold_metrics <- cv$metrics %>%     filter(fold != 0) %>%     pull(rmse)    data.frame(     model = name,     rmse_mean = mean(fold_metrics),     rmse_sd = sd(fold_metrics),     rmse_min = min(fold_metrics),     rmse_max = max(fold_metrics)   ) })  comparison_df <- do.call(rbind, comparison) print(comparison_df)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"statistical-comparison","dir":"Articles","previous_headings":"Model Comparison Framework","what":"Statistical Comparison","title":"Advanced Workflows","text":"Test differences significant:","code":"# Collect fold-level metrics for each model fold_metrics_by_model <- list()  for (name in names(models)) {   cv <- cv_forecast(     as.formula(models[[name]]$features),     data = ts_data,     model = models[[name]]$spec,     h = 6,     n_windows = 10   )    fold_metrics_by_model[[name]] <- cv$metrics %>%     filter(fold != 0) %>%     pull(rmse) }  # Paired t-test between models t.test(   fold_metrics_by_model$lm,   fold_metrics_by_model$xgb,   paired = TRUE )  # Friedman test for multiple models fold_matrix <- do.call(cbind, fold_metrics_by_model) friedman.test(fold_matrix)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"model-serialization","dir":"Articles","previous_headings":"Production Deployment","what":"Model Serialization","title":"Advanced Workflows","text":"","code":"# Fit final model final_model <- fit(   value ~ p(12) + month(),   data = ts_data,   model = lm )  # Save model saveRDS(final_model, \"forecast_model.rds\")  # Load model loaded_model <- readRDS(\"forecast_model.rds\")  # Generate forecasts fc <- forecast(loaded_model, h = 12)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"versioned-model-storage","dir":"Articles","previous_headings":"Production Deployment","what":"Versioned Model Storage","title":"Advanced Workflows","text":"","code":"save_model <- function(model, name, version = NULL) {   if (is.null(version)) {     version <- format(Sys.time(), \"%Y%m%d_%H%M%S\")   }    metadata <- list(     name = name,     version = version,     created = Sys.time(),     formula = deparse(model$spec$formula),     predictors = model$predictors,     n_train = nrow(model$data)   )    filename <- sprintf(\"models/%s_%s.rds\", name, version)   saveRDS(list(model = model, metadata = metadata), filename)    cat(\"Saved:\", filename, \"\\n\")   invisible(filename) }  load_model <- function(path) {   obj <- readRDS(path)   cat(\"Loaded model:\", obj$metadata$name, \"\\n\")   cat(\"Version:\", obj$metadata$version, \"\\n\")   cat(\"Created:\", as.character(obj$metadata$created), \"\\n\")   obj$model }"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"batch-forecasting","dir":"Articles","previous_headings":"Production Deployment","what":"Batch Forecasting","title":"Advanced Workflows","text":"","code":"batch_forecast <- function(model, new_data, h, output_dir) {   # Create TimeSeries from new data   ts_new <- TimeSeries(     new_data,     date = model$meta$date,     groups = model$meta$groups,     frequency = model$meta$frequency   )    # Update model with new history   updated_model <- fit(     formula = model$spec$formula_obj,     data = ts_new,     model = model$model_spec   )    # Generate forecasts   fc <- forecast(updated_model, h = h)    # Save results   timestamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")   filename <- file.path(output_dir, sprintf(\"forecast_%s.csv\", timestamp))   write.csv(fc, filename, row.names = FALSE)    cat(\"Forecasts saved to:\", filename, \"\\n\")   fc }"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"monitoring-and-alerts","dir":"Articles","previous_headings":"Production Deployment","what":"Monitoring and Alerts","title":"Advanced Workflows","text":"","code":"monitor_forecast_accuracy <- function(forecasts, actuals, threshold = 0.2) {   # Join forecasts with actuals   eval_data <- forecasts %>%     inner_join(actuals, by = c(\"date\", \"items\")) %>%     mutate(       error = actual - predicted,       abs_pct_error = abs(error) / abs(actual)     )    # Calculate metrics   metrics <- eval_data %>%     summarise(       rmse = sqrt(mean(error^2)),       mape = mean(abs_pct_error) * 100,       max_error = max(abs(error)),       n_large_errors = sum(abs_pct_error > threshold)     )    # Alert if needed   if (metrics$mape > 20 || metrics$n_large_errors > 5) {     warning(\"Forecast quality degradation detected!\")     # Send alert (email, Slack, etc.)   }    metrics }"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"handling-new-groups-cold-start","dir":"Articles","previous_headings":"Edge Cases and Best Practices","what":"Handling New Groups (Cold Start)","title":"Advanced Workflows","text":"new group appears without history:","code":"# Option 1: Use global model (ignore groups) global_model <- fit(   value ~ p(12) + month(),   data = ts_data,   date = \"date\",   groups = NULL,  # Train on pooled data   model = lm )  # Option 2: Borrow from similar groups # Find similar groups based on recent behavior find_similar_groups <- function(new_group_data, historical_data, n_similar = 5) {   # Calculate group summaries   group_stats <- historical_data %>%     group_by(items) %>%     summarise(       mean_value = mean(value),       trend = coef(lm(value ~ seq_along(value)))[2]     )    # Find closest groups   new_stats <- new_group_data %>%     summarise(       mean_value = mean(value),       trend = coef(lm(value ~ seq_along(value)))[2]     )    group_stats %>%     mutate(distance = sqrt(       (mean_value - new_stats$mean_value)^2 +       (trend - new_stats$trend)^2     )) %>%     arrange(distance) %>%     head(n_similar) %>%     pull(items) }"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"handling-missing-future-exogenous-variables","dir":"Articles","previous_headings":"Edge Cases and Best Practices","what":"Handling Missing Future Exogenous Variables","title":"Advanced Workflows","text":"","code":"# Option 1: Carry forward fc <- forecast(model, h = 12, xreg_strategy = \"carry\")  # Option 2: Use scenario analysis scenarios <- list(   optimistic = data.frame(     date = future_dates,     price = 9.99,     promo = 1   ),   pessimistic = data.frame(     date = future_dates,     price = 12.99,     promo = 0   ),   baseline = data.frame(     date = future_dates,     price = 10.99,     promo = 0.5   ) )  scenario_forecasts <- lapply(names(scenarios), function(name) {   fc <- forecast(model, future = scenarios[[name]])   fc$scenario <- name   fc })  all_scenarios <- do.call(rbind, scenario_forecasts)"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"dealing-with-structural-breaks","dir":"Articles","previous_headings":"Edge Cases and Best Practices","what":"Dealing with Structural Breaks","title":"Advanced Workflows","text":"patterns change dramatically:","code":"# Detect potential break points detect_breaks <- function(ts_data, target_col) {   library(strucchange)   y <- ts_data[[target_col]]   bp <- breakpoints(y ~ 1)   breakdates(bp) }  # Option 1: Only use data after break recent_data <- ts_data %>%   filter(date >= break_date)  # Option 2: Add regime indicator ts_data <- ts_data %>%   mutate(regime = ifelse(date >= break_date, \"new\", \"old\"))  # Include regime in model model <- fit(   value ~ p(12) + month() + regime,   data = ts_data,   model = lm )"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"intermittent-demand-many-zeros","dir":"Articles","previous_headings":"Edge Cases and Best Practices","what":"Intermittent Demand (Many Zeros)","title":"Advanced Workflows","text":"data many zero values:","code":"# Croston's method components ts_data <- ts_data %>%   mutate(     demand_occurred = value > 0,     demand_size = ifelse(demand_occurred, value, NA)   )  # Model demand occurrence (classification) occurrence_model <- fit(   demand_occurred ~ p(12) + dow() + month(),   data = ts_data,   model = glm,   family = binomial() )  # Model demand size (regression on non-zero) size_model <- fit(   demand_size ~ p(12) + dow() + month(),   data = ts_data %>% filter(demand_occurred),   model = lm )  # Combine predictions forecast_intermittent <- function(occurrence_model, size_model, h) {   # Forecast probability   fc_prob <- forecast(occurrence_model, h = h)    # Forecast size   fc_size <- forecast(size_model, h = h)    # Combined forecast = probability × expected size   fc_prob$demand_forecast <- fc_prob$demand_occurred_forecast * fc_size$demand_size_forecast   fc_prob }"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"very-long-horizons","dir":"Articles","previous_headings":"Edge Cases and Best Practices","what":"Very Long Horizons","title":"Advanced Workflows","text":"horizons longer seasonal periods:","code":"# Option 1: Direct forecasting (train separate models) train_direct_models <- function(ts_data, max_horizon = 24) {   models <- list()    for (h in 1:max_horizon) {     # Create target shifted by h periods     data_h <- ts_data %>%       group_by(items) %>%       mutate(target_h = lead(value, h)) %>%       ungroup() %>%       filter(!is.na(target_h))      models[[h]] <- fit(       target_h ~ p(12) + month(),       data = data_h,       date = \"date\",       groups = \"items\",       model = lm     )   }    models }  # Option 2: Ensemble recursive + direct forecast_ensemble <- function(recursive_fc, direct_fc, weights = c(0.5, 0.5)) {   weights[1] * recursive_fc + weights[2] * direct_fc }"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"reducing-computation-time","dir":"Articles","previous_headings":"Performance Optimization","what":"Reducing Computation Time","title":"Advanced Workflows","text":"","code":"# 1. Use C++ path (default when no exogenous variables) fc <- forecast(model, h = 12, use_cpp = TRUE, verbose = TRUE)  # 2. Reduce features # Fewer features = faster fit and predict model_fast <- fit(value ~ p(3) + month(), data = ts_data, model = lm)  # 3. Use faster models # ranger instead of randomForest # lightgbm instead of xgboost for many categories  # 4. Parallelize CV library(future) library(future.apply) plan(multisession, workers = 4)  cv_parallel <- function(formula, data, models, h, n_windows) {   future_lapply(models, function(m) {     cv_forecast(formula, data = data, model = m, h = h, n_windows = n_windows)   }) }"},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"memory-management","dir":"Articles","previous_headings":"Performance Optimization","what":"Memory Management","title":"Advanced Workflows","text":"","code":"# 1. Don't store predictions if not needed cv <- cv_forecast(..., return_predictions = FALSE)  # 2. Process groups in batches process_in_batches <- function(ts_data, batch_size = 10) {   groups <- unique(ts_data$data[[ts_data$groups]])   n_batches <- ceiling(length(groups) / batch_size)    results <- list()   for (i in seq_len(n_batches)) {     start_idx <- (i - 1) * batch_size + 1     end_idx <- min(i * batch_size, length(groups))     batch_groups <- groups[start_idx:end_idx]      batch_data <- ts_data$data %>%       filter(.data[[ts_data$groups]] %in% batch_groups)      # Process batch     results[[i]] <- process_batch(batch_data)      # Clear memory     gc()   }    do.call(rbind, results) }"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"before-fitting","dir":"Articles","previous_headings":"Summary Checklist","what":"Before Fitting","title":"Advanced Workflows","text":"Data sorted groups date trailing NAs target factor levels present training Sufficient history lag orders Frequency correctly specified","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"model-selection","dir":"Articles","previous_headings":"Summary Checklist","what":"Model Selection","title":"Advanced Workflows","text":"Cross-validated appropriate horizon Compared multiple models Checked per-step accuracy degradation Statistical significance improvements Simple model baseline","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"production","dir":"Articles","previous_headings":"Summary Checklist","what":"Production","title":"Advanced Workflows","text":"Model serialization tested Version tracking place Monitoring pipeline ready Edge cases handled (new groups, missing data) Retraining schedule defined","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/advanced-workflows.html","id":"performance","dir":"Articles","previous_headings":"Summary Checklist","what":"Performance","title":"Advanced Workflows","text":"Computation time acceptable Memory usage monitored Parallelization considered CV C++ path enabled possible","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Cross-Validation","text":"Time series cross-validation essential : Evaluating model performance realistically Comparing different models feature sets Tuning hyperparameters Estimating forecast uncertainty Standard k-fold CV doesn’t work time series violates temporal ordering. chronofeat provides cv_forecast() proper time series cross-validation.","code":"library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  data(retail) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic Usage","title":"Cross-Validation","text":"","code":"cv_results <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  print(cv_results) #> Time Series Cross-Validation Results #> ===================================== #>  #> Parameters: #>   Horizon (h): 6 #>   Number of windows: 5 #>   Completed folds: 5 #>   Window type: expanding #>   Step size: 6 #>   Metric: rmse #>  #> Metrics by fold: #>  fold train_start  train_end test_start   test_end n_train n_test     rmse #>     1  1982-04-01 2007-06-01 2007-07-01 2007-12-01   12726    252 44.98922 #>     2  1982-04-01 2007-12-01 2008-01-01 2008-06-01   12978    252 43.20317 #>     3  1982-04-01 2008-06-01 2008-07-01 2008-12-01   13230    252 64.45866 #>     4  1982-04-01 2008-12-01 2009-01-01 2009-06-01   13482    252 54.92877 #>     5  1982-04-01 2009-06-01 2009-07-01 2009-12-01   13734    252 62.57279 #>     0        <NA>       <NA>       <NA>       <NA>      NA   1260 54.73205"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"understanding-the-output","dir":"Articles","previous_headings":"Basic Usage","what":"Understanding the Output","title":"Cross-Validation","text":"output contains: metrics: Per-fold overall performance metrics params: CV configuration parameters predictions (optional): Individual predictions analysis fold = 0 overall (weighted average) metric fold shows training test date ranges n_train n_test show observation counts","code":"cv_results$metrics #>   fold train_start  train_end test_start   test_end n_train n_test     rmse #> 1    1  1982-04-01 2007-06-01 2007-07-01 2007-12-01   12726    252 44.98922 #> 2    2  1982-04-01 2007-12-01 2008-01-01 2008-06-01   12978    252 43.20317 #> 3    3  1982-04-01 2008-06-01 2008-07-01 2008-12-01   13230    252 64.45866 #> 4    4  1982-04-01 2008-12-01 2009-01-01 2009-06-01   13482    252 54.92877 #> 5    5  1982-04-01 2009-06-01 2009-07-01 2009-12-01   13734    252 62.57279 #> 6    0        <NA>       <NA>       <NA>       <NA>      NA   1260 54.73205"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"expanding-window-default","dir":"Articles","previous_headings":"Window Types","what":"Expanding Window (Default)","title":"Cross-Validation","text":"training set grows fold: Best : cases. training data improves model estimates.","code":"Fold 1: [----Train----][Test] Fold 2: [------Train------][Test] Fold 3: [--------Train--------][Test] cv_expanding <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5,   window_type = \"expanding\" )"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"sliding-window","dir":"Articles","previous_headings":"Window Types","what":"Sliding Window","title":"Cross-Validation","text":"Fixed-size training window slides forward: Best : Non-stationary data old patterns don’t apply Models use recent data Testing model performs limited history","code":"Fold 1: [----Train----][Test] Fold 2:    [----Train----][Test] Fold 3:       [----Train----][Test] cv_sliding <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5,   window_type = \"sliding\",   window_size = 120  # Use last 120 observations for training )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"horizon-h","dir":"Articles","previous_headings":"Configuring CV","what":"Horizon (h)","title":"Cross-Validation","text":"Forecast horizon - many steps ahead predict:","code":"# Match your production forecast horizon cv_results <- cv_forecast(   ...,   h = 12  # If you forecast 12 months ahead in production )"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"number-of-windows-n_windows","dir":"Articles","previous_headings":"Configuring CV","what":"Number of Windows (n_windows)","title":"Cross-Validation","text":"windows = reliable estimates, slower:","code":"# Quick check cv_quick <- cv_forecast(..., n_windows = 3)  # Thorough evaluation cv_thorough <- cv_forecast(..., n_windows = 10)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"step-size-step_size","dir":"Articles","previous_headings":"Configuring CV","what":"Step Size (step_size)","title":"Cross-Validation","text":"far move folds (default: h):","code":"# Non-overlapping test sets (default) cv_results <- cv_forecast(..., h = 6, step_size = 6)  # Overlapping for more windows from limited data cv_results <- cv_forecast(..., h = 6, step_size = 1)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"built-in-metrics","dir":"Articles","previous_headings":"Metrics","what":"Built-in Metrics","title":"Cross-Validation","text":"","code":"# Root Mean Squared Error (default) cv_forecast(..., metric = \"rmse\")  # Mean Absolute Error cv_forecast(..., metric = \"mae\")  # Mean Absolute Percentage Error cv_forecast(..., metric = \"mape\")  # Mean Squared Error cv_forecast(..., metric = \"mse\")"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"custom-metrics","dir":"Articles","previous_headings":"Metrics","what":"Custom Metrics","title":"Cross-Validation","text":"Provide function takes (actual, predicted):","code":"# Symmetric MAPE smape <- function(actual, predicted) {   mean(2 * abs(actual - predicted) / (abs(actual) + abs(predicted) + 1e-8)) * 100 }  cv_results <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5,   metric = smape )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"summary-statistics","dir":"Articles","previous_headings":"Analyzing Results","what":"Summary Statistics","title":"Cross-Validation","text":"","code":"summary(cv_results) #> Time Series Cross-Validation Summary #> ==================================== #>  #> Metric: rmse #>   Mean:   54.0305 #>   Median: 54.9288 #>   SD:     9.7660 #>   Min:    43.2032 #>   Max:    64.4587"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"predictions-by-fold","dir":"Articles","previous_headings":"Analyzing Results","what":"Predictions by Fold","title":"Cross-Validation","text":"Request individual predictions detailed analysis:","code":"cv_with_preds <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 3,   return_predictions = TRUE )  head(cv_with_preds$predictions) #> # A tibble: 6 × 5 #>   date       items actual predicted  fold #>   <date>     <fct>  <dbl>     <dbl> <int> #> 1 2008-07-01 V10     330.      323.     1 #> 2 2008-08-01 V10     310.      305.     1 #> 3 2008-09-01 V10     326.      316.     1 #> 4 2008-10-01 V10     342.      358.     1 #> 5 2008-11-01 V10     352.      366.     1 #> 6 2008-12-01 V10     535.      515.     1"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"per-step-accuracy","dir":"Articles","previous_headings":"Analyzing Results","what":"Per-Step Accuracy","title":"Cross-Validation","text":"Analyze accuracy degrades forecast horizon:","code":"# Add step number within each fold predictions <- cv_with_preds$predictions %>%   group_by(fold) %>%   mutate(step = row_number()) %>%   ungroup()  # Calculate RMSE by step step_accuracy <- predictions %>%   group_by(step) %>%   summarise(     rmse = sqrt(mean((actual - predicted)^2)),     mae = mean(abs(actual - predicted)),     n = n()   )  print(step_accuracy)  # Visualize library(ggplot2) ggplot(step_accuracy, aes(x = step, y = rmse)) +   geom_line() +   geom_point() +   labs(     title = \"Forecast Accuracy by Horizon\",     x = \"Steps Ahead\",     y = \"RMSE\"   ) +   theme_minimal()"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"per-group-accuracy-panel-data","dir":"Articles","previous_headings":"Analyzing Results","what":"Per-Group Accuracy (Panel Data)","title":"Cross-Validation","text":"","code":"group_accuracy <- cv_with_preds$predictions %>%   group_by(items) %>%   summarise(     rmse = sqrt(mean((actual - predicted)^2)),     mae = mean(abs(actual - predicted)),     n = n()   ) %>%   arrange(rmse)  # Best performing groups head(group_accuracy)  # Worst performing groups tail(group_accuracy)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"model-comparison","dir":"Articles","previous_headings":"","what":"Model Comparison","title":"Cross-Validation","text":"Compare different models feature sets:","code":"# Model 1: Simple cv_simple <- cv_forecast(   value ~ p(12),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  # Model 2: With seasonality cv_seasonal <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  # Model 3: Complex cv_complex <- cv_forecast(   value ~ p(12) + q(12) + month() + rollsum(12),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  # Compare comparison <- data.frame(   model = c(\"Simple\", \"Seasonal\", \"Complex\"),   rmse = c(     cv_simple$metrics[cv_simple$metrics$fold == 0, \"rmse\"],     cv_seasonal$metrics[cv_seasonal$metrics$fold == 0, \"rmse\"],     cv_complex$metrics[cv_complex$metrics$fold == 0, \"rmse\"]   ) )  print(comparison)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"comparing-different-ml-models","dir":"Articles","previous_headings":"Model Comparison","what":"Comparing Different ML Models","title":"Cross-Validation","text":"","code":"library(randomForest)  # Linear model cv_lm <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  # Random Forest cv_rf <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = randomForest,   h = 6,   n_windows = 5,   ntree = 100 )  # XGBoost (with custom spec) xgb_spec <- list(   fit = function(y, X, ...) {     X_mat <- model.matrix(~ . - 1, data = X)     xgboost::xgboost(data = X_mat, label = y, nrounds = 100, verbose = 0)   },   predict = function(object, newdata, ...) {     X_mat <- model.matrix(~ . - 1, data = newdata)     predict(object, X_mat)   } )  cv_xgb <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = xgb_spec,   h = 6,   n_windows = 5 )"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"model-selection-workflow","dir":"Articles","previous_headings":"","what":"Model Selection Workflow","title":"Cross-Validation","text":"recommended workflow selecting best model:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"establish-baseline","dir":"Articles","previous_headings":"Model Selection Workflow","what":"1. Establish Baseline","title":"Cross-Validation","text":"","code":"# Simple model as baseline cv_baseline <- cv_forecast(   value ~ p(12),   data = ts_data,   model = lm,   h = 6,   n_windows = 5 )  baseline_rmse <- cv_baseline$metrics %>%   filter(fold == 0) %>%   pull(rmse)  cat(\"Baseline RMSE:\", baseline_rmse, \"\\n\")"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"feature-selection","dir":"Articles","previous_headings":"Model Selection Workflow","what":"2. Feature Selection","title":"Cross-Validation","text":"","code":"# Test adding features incrementally features_to_test <- list(   base = \"value ~ p(12)\",   calendar = \"value ~ p(12) + month()\",   rolling = \"value ~ p(12) + month() + rollsum(12)\",   trend = \"value ~ p(12) + month() + rollsum(12) + trend(1)\" )  feature_results <- lapply(names(features_to_test), function(name) {   cv <- cv_forecast(     as.formula(features_to_test[[name]]),     data = ts_data,     model = lm,     h = 6,     n_windows = 5   )   data.frame(     features = name,     rmse = cv$metrics[cv$metrics$fold == 0, \"rmse\"]   ) })  feature_comparison <- do.call(rbind, feature_results) print(feature_comparison)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"model-selection","dir":"Articles","previous_headings":"Model Selection Workflow","what":"3. Model Selection","title":"Cross-Validation","text":"","code":"# Test different models with best features best_formula <- value ~ p(12) + month() + rollsum(12)  models_to_test <- list(   lm = lm,   rf = randomForest,   xgb = xgb_spec  # from above )  model_results <- lapply(names(models_to_test), function(name) {   cv <- cv_forecast(     best_formula,     data = ts_data,     model = models_to_test[[name]],     h = 6,     n_windows = 5   )   data.frame(     model = name,     rmse = cv$metrics[cv$metrics$fold == 0, \"rmse\"]   ) })  model_comparison <- do.call(rbind, model_results) print(model_comparison)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"final-validation","dir":"Articles","previous_headings":"Model Selection Workflow","what":"4. Final Validation","title":"Cross-Validation","text":"","code":"# Hold out the last fold for final validation # Train on all but the most recent data # Test on most recent data only"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"aligned-date-sequences","dir":"Articles","previous_headings":"Panel Data Considerations","what":"Aligned Date Sequences","title":"Cross-Validation","text":"cv_forecast() requires groups identical date sequences: Solutions: Use TimeSeries() fill_time = TRUE complete calendars Filter common date range across groups Perform per-group validation separately","code":"# This will error if groups have different dates cv_results <- cv_forecast(   value ~ p(12) + month(),   data = unbalanced_panel,  # Groups have different dates   groups = \"store\",   ... ) # Error: Cross-validation requires all groups to have identical date sequences"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"per-group-validation","dir":"Articles","previous_headings":"Panel Data Considerations","what":"Per-Group Validation","title":"Cross-Validation","text":"unbalanced panels, validate group separately:","code":"groups <- unique(ts_data$data$items)  group_cv <- lapply(groups, function(g) {   group_data <- ts_data$data %>% filter(items == g)    cv <- tryCatch({     cv_forecast(       value ~ p(12) + month(),       data = group_data,       date = \"date\",       model = lm,       h = 6,       n_windows = 3     )   }, error = function(e) NULL)    if (!is.null(cv)) {     data.frame(       group = g,       rmse = cv$metrics[cv$metrics$fold == 0, \"rmse\"]     )   } else {     NULL   } })  group_cv_results <- do.call(rbind, group_cv)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"match-production-horizon","dir":"Articles","previous_headings":"Best Practices","what":"1. Match Production Horizon","title":"Cross-Validation","text":"","code":"# If you forecast 12 months ahead in production cv_results <- cv_forecast(..., h = 12) # Not h = 1 (too optimistic) or h = 24 (different task)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"use-enough-windows","dir":"Articles","previous_headings":"Best Practices","what":"2. Use Enough Windows","title":"Cross-Validation","text":"","code":"# At least 5 windows for stable estimates cv_results <- cv_forecast(..., n_windows = 5)  # More is better if you have enough data cv_results <- cv_forecast(..., n_windows = 10)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"watch-for-data-leakage","dir":"Articles","previous_headings":"Best Practices","what":"3. Watch for Data Leakage","title":"Cross-Validation","text":"Don’t use future information features Ensure rolling windows backward-looking Don’t tune test data","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"consider-computational-cost","dir":"Articles","previous_headings":"Best Practices","what":"4. Consider Computational Cost","title":"Cross-Validation","text":"","code":"# CV runs fit() n_windows times # For slow models, start with fewer windows cv_quick <- cv_forecast(..., n_windows = 3)  # Then increase for final evaluation cv_final <- cv_forecast(..., n_windows = 10)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"report-variability","dir":"Articles","previous_headings":"Best Practices","what":"5. Report Variability","title":"Cross-Validation","text":"","code":"# Don't just report mean RMSE # Show variability across folds fold_rmse <- cv_results$metrics %>%   filter(fold != 0) %>%   pull(rmse)  cat(\"Mean RMSE:\", mean(fold_rmse), \"\\n\") cat(\"SD RMSE:\", sd(fold_rmse), \"\\n\") cat(\"Range:\", min(fold_rmse), \"-\", max(fold_rmse), \"\\n\")"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"unable-to-create-cv-splits","dir":"Articles","previous_headings":"Troubleshooting","what":"“Unable to create CV splits”","title":"Cross-Validation","text":"Cause: enough data requested windows. Solution: Reduce n_windows h, use data.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"different-results-each-run","dir":"Articles","previous_headings":"Troubleshooting","what":"Different Results Each Run","title":"Cross-Validation","text":"Cause: Random model (e.g., Random Forest) without seed. Solution: Set seed CV:","code":"set.seed(42) cv_results <- cv_forecast(...)"},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"very-different-fold-metrics","dir":"Articles","previous_headings":"Troubleshooting","what":"Very Different Fold Metrics","title":"Cross-Validation","text":"Cause: Non-stationarity, outliers, regime changes. Solutions: Use sliding window non-stationary data Investigate outlier periods Consider different models different regimes","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"high-variability-in-per-step-accuracy","dir":"Articles","previous_headings":"Troubleshooting","what":"High Variability in Per-Step Accuracy","title":"Cross-Validation","text":"Cause: Different difficulty different horizons. Solution: expected! Short-term forecasts usually accurate.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/cross-validation.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Cross-Validation","text":"Key outputs: $metrics - Per-fold overall metrics $predictions - Individual predictions (requested) $params - CV configuration","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Building Custom Models","text":"chronofeat model-agnostic: handles feature engineering recursive forecasting, provide model. article shows integrate machine learning framework chronofeat, simple linear models gradient boosting neural networks.","code":"library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  # Load sample data data(retail) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"the-model-specification-interface","dir":"Articles","previous_headings":"","what":"The Model Specification Interface","title":"Building Custom Models","text":"chronofeat accepts models two forms:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"direct-function-simple-cases","dir":"Articles","previous_headings":"The Model Specification Interface","what":"1. Direct Function (Simple Cases)","title":"Building Custom Models","text":"models standard R interfaces, pass function directly: chronofeat internally converts model specification using as_model_spec().","code":"# Works with lm, glm, randomForest, ranger, etc. m <- fit(value ~ p(12) + month(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"model-specification-full-control","dir":"Articles","previous_headings":"The Model Specification Interface","what":"2. Model Specification (Full Control)","title":"Building Custom Models","text":"complete control, provide list fit predict functions: Key points: X data frame, matrix. Factor columns remain factors. y numeric vector (target column) predict function must return numeric vector","code":"model_spec <- list(   fit = function(y, X, ...) {     # y: numeric vector of target values     # X: data frame of predictor columns     # ...: additional arguments from fit()     # Return: fitted model object   },   predict = function(object, newdata, ...) {     # object: fitted model from fit()     # newdata: data frame with same columns as X     # Return: numeric vector of predictions   } )  m <- fit(value ~ p(12), data = ts_data, model = model_spec)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"basic-linear-regression","dir":"Articles","previous_headings":"Example 1: Linear Models (lm, glm)","what":"Basic Linear Regression","title":"Building Custom Models","text":"simplest approach - pass lm directly:","code":"m_lm <- fit(   value ~ p(12) + month(),   data = ts_data,   model = lm )  fc <- forecast(m_lm, h = 6) head(fc) #> # A tibble: 6 × 3 #>   items date       value_forecast #>   <fct> <date>              <dbl> #> 1 V10   2010-01-01           387. #> 2 V10   2010-02-01           301. #> 3 V10   2010-03-01           352. #> 4 V10   2010-04-01           393. #> 5 V10   2010-05-01           430. #> 6 V10   2010-06-01           402."},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"glm-for-count-data","dir":"Articles","previous_headings":"Example 1: Linear Models (lm, glm)","what":"GLM for Count Data","title":"Building Custom Models","text":"count data, use Poisson Negative Binomial GLM:","code":"# Poisson GLM m_poisson <- fit(  count ~ p(7) + dow() + month(),   data = count_data,   date = \"date\",   groups = \"store\",   model = glm,   family = poisson() )  # Negative Binomial (requires MASS) library(MASS) m_nb <- fit(   count ~ p(7) + dow(),   data = count_data,   date = \"date\",   model = glm.nb )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"regularized-regression-glmnet","dir":"Articles","previous_headings":"Example 1: Linear Models (lm, glm)","what":"Regularized Regression (glmnet)","title":"Building Custom Models","text":"","code":"library(glmnet)  glmnet_spec <- list(   fit = function(y, X, alpha = 1, lambda = NULL, ...) {     # glmnet requires matrix input     # Handle factors by creating model matrix     X_mat <- model.matrix(~ . - 1, data = X)      if (is.null(lambda)) {       # Use cross-validation to select lambda       cv_fit <- cv.glmnet(X_mat, y, alpha = alpha, ...)       lambda <- cv_fit$lambda.min     }      list(       model = glmnet(X_mat, y, alpha = alpha, lambda = lambda, ...),       lambda = lambda,       formula = ~ . - 1  # Store for prediction     )   },   predict = function(object, newdata, ...) {     X_mat <- model.matrix(object$formula, data = newdata)     as.numeric(predict(object$model, newx = X_mat, s = object$lambda))   } )  # Lasso (alpha = 1) m_lasso <- fit(value ~ p(12) + month(), data = ts_data, model = glmnet_spec, alpha = 1)  # Ridge (alpha = 0) m_ridge <- fit(value ~ p(12) + month(), data = ts_data, model = glmnet_spec, alpha = 0)  # Elastic Net (alpha = 0.5) m_enet <- fit(value ~ p(12) + month(), data = ts_data, model = glmnet_spec, alpha = 0.5)"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"example-2-xgboost","dir":"Articles","previous_headings":"","what":"Example 2: XGBoost","title":"Building Custom Models","text":"XGBoost one popular choices time series forecasting.","code":"library(xgboost)  xgb_spec <- list(   fit = function(y, X, nrounds = 100, ...) {     # Convert factors to numeric for XGBoost     X_processed <- X     factor_cols <- sapply(X, is.factor)      if (any(factor_cols)) {       for (col in names(X)[factor_cols]) {         X_processed[[col]] <- as.numeric(X[[col]])       }     }      # Create DMatrix     dtrain <- xgb.DMatrix(data = as.matrix(X_processed), label = y)      # Train model     xgboost(       data = dtrain,       nrounds = nrounds,       verbose = 0,       ...     )   },   predict = function(object, newdata, ...) {     # Same factor conversion     X_processed <- newdata     factor_cols <- sapply(newdata, is.factor)      if (any(factor_cols)) {       for (col in names(newdata)[factor_cols]) {         X_processed[[col]] <- as.numeric(newdata[[col]])       }     }      predict(object, as.matrix(X_processed))   } )  m_xgb <- fit(   value ~ p(12) + q(7, 12) + month() + rollsum(12),   data = ts_data,   model = xgb_spec,   nrounds = 200,   eta = 0.1,   max_depth = 6 )  fc_xgb <- forecast(m_xgb, h = 12)"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"xgboost-with-early-stopping","dir":"Articles","previous_headings":"Example 2: XGBoost","what":"XGBoost with Early Stopping","title":"Building Custom Models","text":"","code":"xgb_early_spec <- list(   fit = function(y, X, nrounds = 1000, early_stopping_rounds = 50, ...) {     # Convert factors     X_processed <- X     factor_cols <- sapply(X, is.factor)     if (any(factor_cols)) {       for (col in names(X)[factor_cols]) {         X_processed[[col]] <- as.numeric(X[[col]])       }     }      # Split for validation (last 20%)     n <- length(y)     val_idx <- seq(floor(n * 0.8) + 1, n)     train_idx <- seq(1, floor(n * 0.8))      dtrain <- xgb.DMatrix(       data = as.matrix(X_processed[train_idx, , drop = FALSE]),       label = y[train_idx]     )     dval <- xgb.DMatrix(       data = as.matrix(X_processed[val_idx, , drop = FALSE]),       label = y[val_idx]     )      xgb.train(       data = dtrain,       watchlist = list(train = dtrain, val = dval),       nrounds = nrounds,       early_stopping_rounds = early_stopping_rounds,       verbose = 0,       ...     )   },   predict = function(object, newdata, ...) {     X_processed <- newdata     factor_cols <- sapply(newdata, is.factor)     if (any(factor_cols)) {       for (col in names(newdata)[factor_cols]) {         X_processed[[col]] <- as.numeric(newdata[[col]])       }     }     predict(object, as.matrix(X_processed))   } )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"example-3-lightgbm","dir":"Articles","previous_headings":"","what":"Example 3: LightGBM","title":"Building Custom Models","text":"LightGBM handles categorical features natively, making convenient time series calendar features.","code":"library(lightgbm)  lgb_spec <- list(   fit = function(y, X, num_iterations = 100, ...) {     # Identify categorical columns     cat_cols <- names(X)[sapply(X, is.factor)]      # Convert factors to integer (0-indexed for LightGBM)     X_processed <- X     for (col in cat_cols) {       X_processed[[col]] <- as.integer(X[[col]]) - 1L     }      # Create dataset with categorical feature specification     dtrain <- lgb.Dataset(       data = as.matrix(X_processed),       label = y,       categorical_feature = cat_cols     )      lgb.train(       data = dtrain,       params = list(         objective = \"regression\",         metric = \"rmse\",         verbosity = -1,         ...       ),       nrounds = num_iterations     )   },   predict = function(object, newdata, ...) {     # Same factor conversion     X_processed <- newdata     cat_cols <- names(newdata)[sapply(newdata, is.factor)]     for (col in cat_cols) {       X_processed[[col]] <- as.integer(newdata[[col]]) - 1L     }      predict(object, as.matrix(X_processed))   } )  m_lgb <- fit(   value ~ p(12) + month() + rollsum(12),   data = ts_data,   model = lgb_spec,   num_iterations = 200,   learning_rate = 0.1,   num_leaves = 31 )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"using-randomforest","dir":"Articles","previous_headings":"Example 4: Random Forest","what":"Using randomForest","title":"Building Custom Models","text":"","code":"library(randomForest)  # Direct usage (works out of the box) m_rf <- fit(   value ~ p(12) + month(),   data = ts_data,   model = randomForest,   ntree = 500 )  fc_rf <- forecast(m_rf, h = 12)"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"using-ranger-faster","dir":"Articles","previous_headings":"Example 4: Random Forest","what":"Using ranger (Faster)","title":"Building Custom Models","text":"ranger faster implementation Random Forest:","code":"library(ranger)  ranger_spec <- list(   fit = function(y, X, ...) {     # ranger uses formula interface     train_df <- cbind(data.frame(.target = y), X)     ranger(.target ~ ., data = train_df, ...)   },   predict = function(object, newdata, ...) {     predict(object, data = newdata)$predictions   } )  m_ranger <- fit(   value ~ p(12) + month(),   data = ts_data,   model = ranger_spec,   num.trees = 500,   mtry = 4 )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"example-5-support-vector-machines","dir":"Articles","previous_headings":"","what":"Example 5: Support Vector Machines","title":"Building Custom Models","text":"","code":"library(e1071)  svm_spec <- list(   fit = function(y, X, ...) {     train_df <- cbind(data.frame(.target = y), X)     svm(.target ~ ., data = train_df, ...)   },   predict = function(object, newdata, ...) {     as.numeric(predict(object, newdata = newdata))   } )  m_svm <- fit(   value ~ p(12) + month(),   data = ts_data,   model = svm_spec,   kernel = \"radial\",   cost = 1,   epsilon = 0.1 )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"example-6-neural-networks-kerastensorflow","dir":"Articles","previous_headings":"","what":"Example 6: Neural Networks (Keras/TensorFlow)","title":"Building Custom Models","text":"","code":"library(keras)  keras_spec <- list(   fit = function(y, X, epochs = 100, batch_size = 32, ...) {     # Convert all to numeric matrix     X_mat <- model.matrix(~ . - 1, data = X)      # Scale features     X_mean <- colMeans(X_mat)     X_sd <- apply(X_mat, 2, sd)     X_sd[X_sd == 0] <- 1  # Avoid division by zero     X_scaled <- scale(X_mat, center = X_mean, scale = X_sd)      # Scale target     y_mean <- mean(y)     y_sd <- sd(y)     y_scaled <- (y - y_mean) / y_sd      # Build model     model <- keras_model_sequential() %>%       layer_dense(units = 64, activation = \"relu\", input_shape = ncol(X_scaled)) %>%       layer_dropout(rate = 0.2) %>%       layer_dense(units = 32, activation = \"relu\") %>%       layer_dropout(rate = 0.2) %>%       layer_dense(units = 1)      model %>% compile(       loss = \"mse\",       optimizer = optimizer_adam(learning_rate = 0.001)     )      # Train     model %>% keras::fit(       X_scaled, y_scaled,       epochs = epochs,       batch_size = batch_size,       validation_split = 0.2,       verbose = 0,       callbacks = list(         callback_early_stopping(patience = 10, restore_best_weights = TRUE)       )     )      # Return model with scaling parameters     list(       model = model,       X_mean = X_mean,       X_sd = X_sd,       y_mean = y_mean,       y_sd = y_sd,       formula = ~ . - 1     )   },   predict = function(object, newdata, ...) {     X_mat <- model.matrix(object$formula, data = newdata)     X_scaled <- scale(X_mat, center = object$X_mean, scale = object$X_sd)      y_scaled <- predict(object$model, X_scaled)     as.numeric(y_scaled * object$y_sd + object$y_mean)   } )  m_keras <- fit(   value ~ p(12) + month(),   data = ts_data,   model = keras_spec,   epochs = 100,   batch_size = 64 )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"example-7-ensemble-models","dir":"Articles","previous_headings":"","what":"Example 7: Ensemble Models","title":"Building Custom Models","text":"Combine multiple models robust predictions:","code":"ensemble_spec <- list(   fit = function(y, X, ...) {     # Train multiple models     train_df <- cbind(data.frame(.target = y), X)      models <- list(       lm = lm(.target ~ ., data = train_df),       rf = randomForest::randomForest(.target ~ ., data = train_df, ntree = 200)     )      # Optional: train XGBoost     X_mat <- model.matrix(~ . - 1, data = X)     models$xgb <- xgboost::xgboost(       data = X_mat, label = y,       nrounds = 100, verbose = 0     )      list(models = models, formula = ~ . - 1)   },   predict = function(object, newdata, ...) {     # Get predictions from each model     pred_lm <- predict(object$models$lm, newdata = newdata)     pred_rf <- predict(object$models$rf, newdata = newdata)      X_mat <- model.matrix(object$formula, data = newdata)     pred_xgb <- predict(object$models$xgb, X_mat)      # Simple average (could use weighted average or stacking)     (pred_lm + pred_rf + pred_xgb) / 3   } )  m_ensemble <- fit(   value ~ p(12) + month() + rollsum(12),   data = ts_data,   model = ensemble_spec )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"weighted-ensemble-based-on-cv-performance","dir":"Articles","previous_headings":"Example 7: Ensemble Models","what":"Weighted Ensemble Based on CV Performance","title":"Building Custom Models","text":"","code":"weighted_ensemble_spec <- list(   fit = function(y, X, ...) {     train_df <- cbind(data.frame(.target = y), X)     n <- nrow(train_df)      # Train-validation split for weight estimation     train_idx <- 1:floor(n * 0.8)     val_idx <- (floor(n * 0.8) + 1):n      train_sub <- train_df[train_idx, ]     val_sub <- train_df[val_idx, ]     y_val <- val_sub$.target      # Train models on training subset     m_lm <- lm(.target ~ ., data = train_sub)     m_rf <- randomForest::randomForest(.target ~ ., data = train_sub, ntree = 200)      # Evaluate on validation     pred_lm_val <- predict(m_lm, val_sub)     pred_rf_val <- predict(m_rf, val_sub)      rmse_lm <- sqrt(mean((y_val - pred_lm_val)^2))     rmse_rf <- sqrt(mean((y_val - pred_rf_val)^2))      # Inverse RMSE weighting     w_lm <- 1 / rmse_lm     w_rf <- 1 / rmse_rf     w_sum <- w_lm + w_rf     weights <- c(lm = w_lm / w_sum, rf = w_rf / w_sum)      # Retrain on full data     models <- list(       lm = lm(.target ~ ., data = train_df),       rf = randomForest::randomForest(.target ~ ., data = train_df, ntree = 200)     )      list(models = models, weights = weights)   },   predict = function(object, newdata, ...) {     pred_lm <- predict(object$models$lm, newdata = newdata)     pred_rf <- predict(object$models$rf, newdata = newdata)      object$weights[\"lm\"] * pred_lm + object$weights[\"rf\"] * pred_rf   } )"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"handling-factor-variables","dir":"Articles","previous_headings":"","what":"Handling Factor Variables","title":"Building Custom Models","text":"chronofeat passes factor columns -model. Different models handle factors differently:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"converting-factors-for-tree-models","dir":"Articles","previous_headings":"Handling Factor Variables","what":"Converting Factors for Tree Models","title":"Building Custom Models","text":"","code":"# For models that need numeric input convert_factors <- function(X) {   X_processed <- X   for (col in names(X)) {     if (is.factor(X[[col]])) {       X_processed[[col]] <- as.numeric(X[[col]])     }   }   X_processed }  # For models that need one-hot encoding one_hot_encode <- function(X) {   model.matrix(~ . - 1, data = X) }"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"prediction-intervals","dir":"Articles","previous_headings":"","what":"Prediction Intervals","title":"Building Custom Models","text":"chronofeat’s forecast() returns point predictions. prediction intervals, implement model specification:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"quantile-regression-with-lightgbm","dir":"Articles","previous_headings":"Prediction Intervals","what":"Quantile Regression with LightGBM","title":"Building Custom Models","text":"","code":"lgb_quantile_spec <- list(   fit = function(y, X, quantiles = c(0.1, 0.5, 0.9), num_iterations = 100, ...) {     X_mat <- as.matrix(convert_factors(X))      models <- list()     for (q in quantiles) {       dtrain <- lgb.Dataset(data = X_mat, label = y)       models[[as.character(q)]] <- lgb.train(         data = dtrain,         params = list(           objective = \"quantile\",           alpha = q,           metric = \"quantile\",           verbosity = -1         ),         nrounds = num_iterations       )     }     list(models = models, quantiles = quantiles)   },   predict = function(object, newdata, ...) {     X_mat <- as.matrix(convert_factors(newdata))      # Return median (0.5 quantile) as point prediction     predict(object$models[[\"0.5\"]], X_mat)   } )  # Extend forecast to get intervals forecast_with_intervals <- function(model, h, quantiles = c(0.1, 0.5, 0.9)) {   # ... custom implementation }"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"bootstrap-prediction-intervals","dir":"Articles","previous_headings":"Prediction Intervals","what":"Bootstrap Prediction Intervals","title":"Building Custom Models","text":"","code":"bootstrap_intervals <- function(model, h, n_boot = 100, conf_level = 0.95) {   # Store original predictions   fc_orig <- forecast(model, h = h)    # Bootstrap: resample residuals and reforecast   # ... implementation depends on model type }"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"checking-feature-importance","dir":"Articles","previous_headings":"Model Diagnostics","what":"Checking Feature Importance","title":"Building Custom Models","text":"","code":"# For XGBoost importance_xgb <- xgb.importance(model = m_xgb$model_obj) xgb.plot.importance(importance_xgb, top_n = 15)  # For Random Forest importance_rf <- importance(m_rf$model_obj) varImpPlot(m_rf$model_obj)  # For LightGBM importance_lgb <- lgb.importance(m_lgb$model_obj) lgb.plot.importance(importance_lgb, top_n = 15)"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"residual-analysis","dir":"Articles","previous_headings":"Model Diagnostics","what":"Residual Analysis","title":"Building Custom Models","text":"","code":"# Get training data with predictions train_data <- model$data y_actual <- train_data[[model$spec$target]] y_pred <- predict(model$model_obj, newdata = train_data[, model$predictors])  residuals <- y_actual - y_pred  # Plot residuals par(mfrow = c(2, 2)) plot(y_pred, residuals, main = \"Residuals vs Fitted\") abline(h = 0, col = \"red\") hist(residuals, main = \"Residual Distribution\", breaks = 30) qqnorm(residuals) qqline(residuals) acf(residuals, main = \"Residual ACF\")"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"column-not-found-error","dir":"Articles","previous_headings":"Troubleshooting Common Issues","what":"1. “Column not found” Error","title":"Building Custom Models","text":"Cause: Feature names newdata don’t match training. Solution: Check predict function receives column names:","code":"# Debug: print column names predict = function(object, newdata, ...) {   cat(\"Columns:\", paste(names(newdata), collapse = \", \"), \"\\n\")   # ... }"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"na-predictions","dir":"Articles","previous_headings":"Troubleshooting Common Issues","what":"2. NA Predictions","title":"Building Custom Models","text":"Cause: Model returns NA factor levels seen training, NaN numeric issues. Solution: Handle unknown levels validate predictions:","code":"predict = function(object, newdata, ...) {   pred <- predict(object$model, newdata)   pred[is.na(pred)] <- object$fallback_value   pred }"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"factor-level-mismatch","dir":"Articles","previous_headings":"Troubleshooting Common Issues","what":"3. Factor Level Mismatch","title":"Building Custom Models","text":"Cause: New factor levels appear forecasting (e.g., forecasting December training Jan-Nov). Solution: Ensure training data covers levels, handle gracefully:","code":"# chronofeat converts unknown levels to NA automatically # Your model should handle NA gracefully or use numeric encoding  # For tree models: convert to numeric X[[col]] <- as.numeric(X[[col]])"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"memory-issues-with-large-data","dir":"Articles","previous_headings":"Troubleshooting Common Issues","what":"4. Memory Issues with Large Data","title":"Building Custom Models","text":"Solution: Use efficient implementations:","code":"# Use ranger instead of randomForest # Use data.table backend if available # Reduce number of trees/iterations for debugging"},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"slow-forecasting","dir":"Articles","previous_headings":"Troubleshooting Common Issues","what":"5. Slow Forecasting","title":"Building Custom Models","text":"Cause: Recursive forecasting calls predict() h times per group. Solutions: Use C++ accelerated path (default exogenous variables) Simplify model faster predictions Reduce forecast horizon","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/custom-models.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Building Custom Models","text":"Creating custom model specifications chronofeat requires: fit function takes (y, X, ...) returns model object predict function takes (object, newdata, ...) returns numeric predictions Key considerations: Handle factor columns appropriately model type Store preprocessing parameters (scaling, encoding) model object Return predictions numeric vector matching input row count Test specification small subset running full data See Advanced Workflows article hyperparameter tuning production deployment patterns.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Feature Engineering Reference","text":"article provides complete reference features available chronofeat’s formula interface. Features automatically generated fit() regenerated identically forecast().","code":"library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  data(retail) ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"target-features","dir":"Articles","previous_headings":"","what":"Target Features","title":"Feature Engineering Reference","text":"Target features derived variable ’re forecasting.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"lags-p","dir":"Articles","previous_headings":"Target Features","what":"Lags: p()","title":"Feature Engineering Reference","text":"Create lagged values target variable. works forecasting: step 1: value_lag_1 uses last actual observation step 2: value_lag_1 uses step-1 prediction recursively Best practices: daily data weekly seasonality: p(1, 7, 14) p(7) monthly data yearly seasonality: p(1, 12) p(12) Fewer lags = less data lost NA, simpler model lags = captures longer patterns needs history","code":"# Create 12 consecutive lags (lag_1 through lag_12) m <- fit(value ~ p(12), data = ts_data, model = lm) m$predictors #>  [1] \"value_lag_1\"  \"value_lag_2\"  \"value_lag_3\"  \"value_lag_4\"  \"value_lag_5\"  #>  [6] \"value_lag_6\"  \"value_lag_7\"  \"value_lag_8\"  \"value_lag_9\"  \"value_lag_10\" #> [11] \"value_lag_11\" \"value_lag_12\" # Create specific lags only m <- fit(value ~ p(1, 7, 12, 24), data = ts_data, model = lm) # Creates: value_lag_1, value_lag_7, value_lag_12, value_lag_24"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"moving-averages-q","dir":"Articles","previous_headings":"Target Features","what":"Moving Averages: q()","title":"Feature Engineering Reference","text":"Create moving averages target specified windows. works: q(7) = mean last 7 values (including current) Uses slider::slide_dbl() .complete = TRUE (returns NA window incomplete) Best practices: Captures level/trend without lag-specific patterns Combine lags: value ~ p(12) + q(12) provides forecasting, early steps may incomplete windows (returns NA)","code":"# Single window m <- fit(value ~ q(12), data = ts_data, model = lm) m$predictors #> [1] \"value_ma_12\"  # Multiple windows m <- fit(value ~ q(3, 6, 12), data = ts_data, model = lm) m$predictors #> [1] \"value_ma_3\"  \"value_ma_6\"  \"value_ma_12\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"rolling-statistics","dir":"Articles","previous_headings":"Target Features","what":"Rolling Statistics","title":"Feature Engineering Reference","text":"Calculate rolling statistics specified windows.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"rolling-sum-rollsum","dir":"Articles","previous_headings":"Target Features > Rolling Statistics","what":"Rolling Sum: rollsum()","title":"Feature Engineering Reference","text":"Useful cumulative metrics (total sales period).","code":"m <- fit(value ~ rollsum(6, 12), data = ts_data, model = lm) m$predictors #> [1] \"value_rollsum_6\"  \"value_rollsum_12\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"rolling-standard-deviation-rollsd","dir":"Articles","previous_headings":"Target Features > Rolling Statistics","what":"Rolling Standard Deviation: rollsd()","title":"Feature Engineering Reference","text":"Captures volatility/variability patterns.","code":"m <- fit(value ~ rollsd(12), data = ts_data, model = lm) m$predictors #> [1] \"value_rollsd_12\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"rolling-minmax-rollmin-rollmax","dir":"Articles","previous_headings":"Target Features > Rolling Statistics","what":"Rolling Min/Max: rollmin(), rollmax()","title":"Feature Engineering Reference","text":"Useful range-based patterns.","code":"m <- fit(value ~ rollmin(12) + rollmax(12), data = ts_data, model = lm) m$predictors #> [1] \"value_rollmin_12\" \"value_rollmax_12\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"rolling-slope-rollslope","dir":"Articles","previous_headings":"Target Features > Rolling Statistics","what":"Rolling Slope: rollslope()","title":"Feature Engineering Reference","text":"Captures local trend direction strength. Computed slope linear regression window. Important behavior forecasting: Rolling statistics return NA available history shorter requested window. matches training behavior incomplete windows produce NA.","code":"m <- fit(value ~ rollslope(12), data = ts_data, model = lm) m$predictors #> [1] \"value_rollslope_12\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"trend-trend","dir":"Articles","previous_headings":"Target Features","what":"Trend: trend()","title":"Feature Engineering Reference","text":"Add polynomial trend features (time index raised powers). works: trend(1) = row number (1, 2, 3, …) trend(2) = row number squared forecasting, continues incrementing (trained 100 rows, forecast step 1 = 101) Caution: High-degree polynomials can extrapolate wildly. Prefer trend(1) use regularization.","code":"# Linear trend m <- fit(value ~ p(12) + trend(1), data = ts_data, model = lm) m$predictors #>  [1] \"value_lag_1\"  \"value_lag_2\"  \"value_lag_3\"  \"value_lag_4\"  \"value_lag_5\"  #>  [6] \"value_lag_6\"  \"value_lag_7\"  \"value_lag_8\"  \"value_lag_9\"  \"value_lag_10\" #> [11] \"value_lag_11\" \"value_lag_12\" \"trend1\"  # Quadratic trend m <- fit(value ~ p(12) + trend(1, 2), data = ts_data, model = lm) m$predictors #>  [1] \"value_lag_1\"  \"value_lag_2\"  \"value_lag_3\"  \"value_lag_4\"  \"value_lag_5\"  #>  [6] \"value_lag_6\"  \"value_lag_7\"  \"value_lag_8\"  \"value_lag_9\"  \"value_lag_10\" #> [11] \"value_lag_11\" \"value_lag_12\" \"trend1\"       \"trend2\""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"calendar-features","dir":"Articles","previous_headings":"","what":"Calendar Features","title":"Feature Engineering Reference","text":"Calendar features capture seasonal patterns based date.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"day-of-week-dow","dir":"Articles","previous_headings":"Calendar Features","what":"Day of Week: dow()","title":"Feature Engineering Reference","text":"daily data, captures within-week patterns (e.g., weekend effects).","code":"# dow() returns an ordered factor: Monday, Tuesday, ..., Sunday m <- fit(value ~ p(7) + dow(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"month-month","dir":"Articles","previous_headings":"Calendar Features","what":"Month: month()","title":"Feature Engineering Reference","text":"Captures monthly seasonality (common retail, energy, etc.).","code":"# month() returns a factor: 01, 02, ..., 12 m <- fit(value ~ p(12) + month(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"week-of-year-woy","dir":"Articles","previous_headings":"Calendar Features","what":"Week of Year: woy()","title":"Feature Engineering Reference","text":"Captures week-level seasonality. Useful weekly data daily data week number matters.","code":"# woy() returns integer: 1-53 m <- fit(value ~ p(7) + woy(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"end-of-month-eom","dir":"Articles","previous_headings":"Calendar Features","what":"End of Month: eom()","title":"Feature Engineering Reference","text":"Captures end--month effects (common finance, billing cycles).","code":"# eom() returns 0/1 indicator m <- fit(value ~ p(12) + eom(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"day-of-month-dom","dir":"Articles","previous_headings":"Calendar Features","what":"Day of Month: dom()","title":"Feature Engineering Reference","text":"Captures within-month patterns (e.g., payday effects).","code":"# dom() returns integer: 1-31 m <- fit(value ~ p(12) + dom(), data = ts_data, model = lm)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"combining-calendar-features","dir":"Articles","previous_headings":"Calendar Features","what":"Combining Calendar Features","title":"Feature Engineering Reference","text":"Important: Calendar features create factor levels. Ensure training data covers levels ’ll encounter forecasting. train Jan-Nov forecast December, month = 12 level unknown converted NA.","code":"# For daily retail data value ~ p(7) + dow() + month() + eom()  # For hourly data (if using POSIXct) value ~ p(24) + dow() + month() + hod()  # hour of day"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"exogenous-variable-features","dir":"Articles","previous_headings":"","what":"Exogenous Variable Features","title":"Feature Engineering Reference","text":"Include external predictors model.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"raw-variables","dir":"Articles","previous_headings":"Exogenous Variable Features","what":"Raw Variables","title":"Feature Engineering Reference","text":"Include column directly (transformation): forecasting, must provide future values via future parameter:","code":"# Assume data has 'price' and 'promo' columns m <- fit(value ~ p(12) + price + promo, data = ts_data, model = lm) future_data <- data.frame(   date = seq(as.Date(\"2024-01-01\"), by = \"month\", length.out = 12),   items = \"item_1\",   price = rep(9.99, 12),   promo = c(1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1) )  fc <- forecast(m, future = future_data)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"lagged-exogenous-lag","dir":"Articles","previous_headings":"Exogenous Variable Features","what":"Lagged Exogenous: lag()","title":"Feature Engineering Reference","text":"Create lags exogenous variables: Lag 0 includes current value exogenous variable.","code":"# lag(variable, lag1, lag2, ...) m <- fit(value ~ p(12) + lag(price, 0, 1, 7), data = ts_data, model = lm) # Creates: price (lag 0 = current), price_lag_1, price_lag_7"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"moving-average-of-exogenous-ma","dir":"Articles","previous_headings":"Exogenous Variable Features","what":"Moving Average of Exogenous: ma()","title":"Feature Engineering Reference","text":"","code":"# ma(variable, window1, window2, ...) m <- fit(value ~ p(12) + ma(price, 7, 28), data = ts_data, model = lm) # Creates: price_ma_7, price_ma_28"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"combining-exogenous-features","dir":"Articles","previous_headings":"Exogenous Variable Features","what":"Combining Exogenous Features","title":"Feature Engineering Reference","text":"","code":"# Full exogenous specification m <- fit(   value ~ p(12) + month() +     price + lag(price, 1, 7) + ma(price, 7) +     promo,   data = ts_data,   model = lm )"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"feature-combinations","dir":"Articles","previous_headings":"","what":"Feature Combinations","title":"Feature Engineering Reference","text":"recommended feature sets common scenarios:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"basic-autoregressive","dir":"Articles","previous_headings":"Feature Combinations","what":"Basic Autoregressive","title":"Feature Engineering Reference","text":"","code":"# Simple: just lags value ~ p(12)  # With moving average value ~ p(12) + q(12)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"seasonal-calendar-based","dir":"Articles","previous_headings":"Feature Combinations","what":"Seasonal (Calendar-based)","title":"Feature Engineering Reference","text":"","code":"# Monthly data with yearly seasonality value ~ p(12) + month()  # Daily data with weekly + yearly value ~ p(7) + dow() + month()  # Daily with all calendar value ~ p(7) + dow() + month() + woy() + eom()"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"trend-seasonality","dir":"Articles","previous_headings":"Feature Combinations","what":"Trend + Seasonality","title":"Feature Engineering Reference","text":"","code":"# Linear trend + monthly seasonality value ~ p(12) + trend(1) + month()  # Quadratic trend (use cautiously) value ~ p(12) + trend(1, 2) + month()"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"with-rolling-statistics","dir":"Articles","previous_headings":"Feature Combinations","what":"With Rolling Statistics","title":"Feature Engineering Reference","text":"","code":"# Capture level, volatility, and trend value ~ p(12) + q(12) + rollsd(12) + rollslope(12)  # Multiple windows for short and long patterns value ~ p(12) + rollsum(7, 28) + rollsd(7, 28)"},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"with-exogenous-variables","dir":"Articles","previous_headings":"Feature Combinations","what":"With Exogenous Variables","title":"Feature Engineering Reference","text":"","code":"# Price effects value ~ p(12) + month() + price + lag(price, 1, 7)  # Full model value ~ p(12) + q(12) + month() + dow() +         price + lag(price, 1, 7) + ma(price, 7) +         promo + rollslope(12)"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"start-simple","dir":"Articles","previous_headings":"Choosing Features","what":"Start Simple","title":"Feature Engineering Reference","text":"Start p(k) + month() k matches seasonality Check residuals remaining patterns Add features incrementally Use cross-validation compare","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"feature-behavior-during-forecasting","dir":"Articles","previous_headings":"","what":"Feature Behavior During Forecasting","title":"Feature Engineering Reference","text":"Understanding features behave recursive forecasting crucial:","code":""},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"na-handling","dir":"Articles","previous_headings":"Feature Behavior During Forecasting","what":"NA Handling","title":"Feature Engineering Reference","text":"Rows NA features dropped training forecasting, NA features → NA predictions step Choose window sizes appropriate forecast horizon","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/feature-engineering.html","id":"low-level-feature-functions","dir":"Articles","previous_headings":"","what":"Low-Level Feature Functions","title":"Feature Engineering Reference","text":"manual feature engineering outside formula interface:","code":"# Create lags and MAs manually df_feat <- feat_lag_ma_dt(   df = my_data,   date = \"date\",   target = \"sales\",   groups = \"store\",   p = 12,          # 12 lags   q = c(7, 28)     # 7-day and 28-day MAs )  # Add calendar features df_feat <- feat_calendar_dt(   df = df_feat,   date = date,   dow = TRUE,   month = TRUE,   woy = FALSE,   eom = TRUE,   dom = FALSE )  # Add rolling statistics df_feat <- feat_rolling_dt(   df = df_feat,   date = \"date\",   target = \"sales\",   groups = \"store\",   windows = c(7, 28),   stats = c(\"sum\", \"sd\"),   trend_windows = 28 )  # Add trend df_feat <- feat_trend(   df = df_feat,   date = \"date\",   groups = \"store\",   degrees = c(1, 2) )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started with chronofeat","text":"chronofeat R package time series feature engineering forecasting. provides: Formula-based feature specification: Define lags, moving averages, rolling statistics, calendar features using concise formula syntax Model-agnostic design: Works R model fit/predict interface (lm, glm, xgboost, randomForest, etc.) Recursive multi-step forecasting: Automatically generates features forecast step Panel data support: Handle multiple time series (groups) single workflow","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with chronofeat","text":"","code":"# Install from GitHub remotes::install_github(\"quantics/chronofeat\") library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"quick-start","dir":"Articles","previous_headings":"","what":"Quick Start","title":"Getting Started with chronofeat","text":"typical chronofeat workflow three steps: Prepare data TimeSeries() (optional recommended) Fit model fit() using feature formula Generate forecasts forecast()","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"step-1-load-and-prepare-data","dir":"Articles","previous_headings":"Quick Start","what":"Step 1: Load and Prepare Data","title":"Getting Started with chronofeat","text":"chronofeat includes sample retail sales dataset 42 product categories (items) monthly observations: Create TimeSeries object bundle data frequency information: TimeSeries object: Automatically sorts data groups date Detects validates time frequency Provides optional preprocessing (gap-filling, calendar completion)","code":"data(retail) head(retail) #> # A tibble: 6 × 3 #>   date       items value #>   <date>     <fct> <dbl> #> 1 1982-04-01 V10    94   #> 2 1982-05-01 V10   106.  #> 3 1982-06-01 V10    95.1 #> 4 1982-07-01 V10    95.3 #> 5 1982-08-01 V10    82.8 #> 6 1982-09-01 V10    89.4 ts_data <- TimeSeries(   data = retail,   date = \"date\",   groups = \"items\",   frequency = \"month\" )  ts_data #> TimeSeries object #> ---------------- #> Date column: date ( Date ) #> Frequency: month  #> Groups: items  #> Observations: 13986  #>  #> Data (first few rows): #> # A tibble: 6 × 3 #>   date       items value #>   <date>     <fct> <dbl> #> 1 1982-04-01 V10    94   #> 2 1982-05-01 V10   106.  #> 3 1982-06-01 V10    95.1 #> 4 1982-07-01 V10    95.3 #> 5 1982-08-01 V10    82.8 #> 6 1982-09-01 V10    89.4"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"step-2-fit-a-model","dir":"Articles","previous_headings":"Quick Start","what":"Step 2: Fit a Model","title":"Getting Started with chronofeat","text":"Use fit() formula specify target variable features: formula creates: p(12): 12 lags target (value_lag_1 value_lag_12) q(7, 12): 7-period 12-period moving averages month(): Month factor variable model object contains fitted model metadata needed forecasting:","code":"model <- fit(   value ~ p(12) + q(7, 12) + month(),   data = ts_data,   model = lm ) # Check what predictors were created model$predictors #>  [1] \"value_lag_1\"  \"value_lag_2\"  \"value_lag_3\"  \"value_lag_4\"  \"value_lag_5\"  #>  [6] \"value_lag_6\"  \"value_lag_7\"  \"value_lag_8\"  \"value_lag_9\"  \"value_lag_10\" #> [11] \"value_lag_11\" \"value_lag_12\" \"value_ma_7\"   \"value_ma_12\"  \"month\""},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"step-3-generate-forecasts","dir":"Articles","previous_headings":"Quick Start","what":"Step 3: Generate Forecasts","title":"Getting Started with chronofeat","text":"Use forecast() generate multi-step ahead predictions: forecast recursive: predicted value becomes history generating features next step.","code":"fc <- forecast(model, h = 6) #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning in predict.lm(object, newdata = newdata, ...): prediction from #> rank-deficient fit; attr(*, \"non-estim\") has doubtful cases head(fc) #> # A tibble: 6 × 3 #>   items date       value_forecast #>   <fct> <date>              <dbl> #> 1 V10   2010-01-01           380. #> 2 V10   2010-02-01           357. #> 3 V10   2010-03-01           344. #> 4 V10   2010-04-01           364. #> 5 V10   2010-05-01           378. #> 6 V10   2010-06-01           409."},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"visualizing-results","dir":"Articles","previous_headings":"Quick Start","what":"Visualizing Results","title":"Getting Started with chronofeat","text":"","code":"library(ggplot2)  # Get one item for plotting item_a <- retail %>%   filter(items == levels(items)[1]) %>%   tail(36)  fc_a <- fc %>%   filter(items == levels(retail$items)[1])  ggplot() +   geom_line(data = item_a, aes(x = date, y = value), color = \"black\") +   geom_line(data = fc_a, aes(x = date, y = value_forecast), color = \"blue\") +   geom_point(data = fc_a, aes(x = date, y = value_forecast), color = \"blue\") +   labs(title = \"Actual vs Forecast\", x = \"Date\", y = \"Value\") +   theme_minimal()"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"understanding-the-formula-syntax","dir":"Articles","previous_headings":"","what":"Understanding the Formula Syntax","title":"Getting Started with chronofeat","text":"formula’s left side specifies target variable. right side specifies features:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"example-formulas","dir":"Articles","previous_headings":"Understanding the Formula Syntax","what":"Example Formulas","title":"Getting Started with chronofeat","text":"","code":"# Basic autoregressive model value ~ p(12)  # Add calendar seasonality value ~ p(12) + month() + dow()  # Add rolling statistics value ~ p(12) + q(7) + rollsum(7, 28) + rollsd(7)  # Include exogenous variable with lags value ~ p(12) + lag(price, 0, 1, 7) + promo  # Complex model value ~ p(1, 7, 12) + q(7, 28) + month() + dow() + rollslope(12) + trend(1)"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"using-different-models","dir":"Articles","previous_headings":"","what":"Using Different Models","title":"Getting Started with chronofeat","text":"chronofeat works model standard R interface. Pass model function directly: control, provide custom model specification fit predict functions: See Building Custom Models article detailed examples XGBoost, LightGBM, frameworks.","code":"# Linear regression m_lm <- fit(value ~ p(12) + month(), data = ts_data, model = lm)  # GLM for count data m_glm <- fit(count ~ p(7) + dow(), data = count_data,              date = \"date\", model = glm, family = poisson())  # Random Forest library(randomForest) m_rf <- fit(value ~ p(12) + month(), data = ts_data, model = randomForest) xgb_spec <- list(   fit = function(y, X, ...) {     xgboost::xgboost(       data = as.matrix(X),       label = y,       nrounds = 100,       verbose = 0,       ...     )   },   predict = function(object, newdata, ...) {     predict(object, as.matrix(newdata))   } )  m_xgb <- fit(value ~ p(12) + month(), data = ts_data, model = xgb_spec)"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"panel-data-multiple-time-series","dir":"Articles","previous_headings":"","what":"Panel Data (Multiple Time Series)","title":"Getting Started with chronofeat","text":"chronofeat handles panel data (multiple time series) groups parameter. group gets : Lag MA calculations (cross-contamination) Forecasts (predictions stay within group boundaries)","code":"# The retail dataset has 42 items n_distinct(retail$items) #> [1] 42  # fit() handles all groups automatically model <- fit(   value ~ p(12) + month(),   data = ts_data,   model = lm )  # forecast() produces forecasts for each group fc <- forecast(model, h = 3) fc %>%   group_by(items) %>%   summarise(n = n()) %>%   head() #> # A tibble: 6 × 2 #>   items     n #>   <fct> <int> #> 1 V10       3 #> 2 V11       3 #> 3 V12       3 #> 4 V13       3 #> 5 V14       3 #> 6 V15       3"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-Validation","title":"Getting Started with chronofeat","text":"Evaluate model performance time series cross-validation: See Cross-Validation article details.","code":"cv_results <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = lm,   h = 6,   n_windows = 5,   metric = \"rmse\" )  print(cv_results)"},{"path":"https://taf-society.github.io/chronofeat/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Getting Started with chronofeat","text":"Building Custom Models: Learn integrate XGBoost, LightGBM, neural networks, custom ensembles Feature Engineering Reference: Complete guide available features Data Preprocessing: Handle missing dates, gaps, irregular calendars Cross-Validation: Proper evaluation workflows time series Advanced Workflows: Hyperparameter tuning, model comparison, production patterns","code":""},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Data Preprocessing","text":"Real-world time series data often issues: Irregular calendars: Missing dates (weekends, holidays, outages) Target gaps: Missing values variable want forecast Exogenous gaps: Missing values predictor variables TimeSeries() function provides complete preprocessing pipeline handle three problems single, auditable workflow.","code":"library(chronofeat) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"the-timeseries-object","dir":"Articles","previous_headings":"","what":"The TimeSeries Object","title":"Data Preprocessing","text":"TimeSeries() creates object bundles data metadata:","code":"data(retail)  ts_data <- TimeSeries(   data = retail,   date = \"date\",   groups = \"items\",   frequency = \"month\" )  ts_data #> TimeSeries object #> ---------------- #> Date column: date ( Date ) #> Frequency: month  #> Groups: items  #> Observations: 13986  #>  #> Data (first few rows): #> # A tibble: 6 × 3 #>   date       items value #>   <date>     <fct> <dbl> #> 1 1982-04-01 V10    94   #> 2 1982-05-01 V10   106.  #> 3 1982-06-01 V10    95.1 #> 4 1982-07-01 V10    95.3 #> 5 1982-08-01 V10    82.8 #> 6 1982-09-01 V10    89.4"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"what-timeseries-does","dir":"Articles","previous_headings":"The TimeSeries Object","what":"What TimeSeries Does","title":"Data Preprocessing","text":"Validates date column (must Date POSIXct) Sorts data groups date (critical lag calculations) Detects validates time frequency Optionally completes time grid fills gaps","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"accessing-the-data","dir":"Articles","previous_headings":"The TimeSeries Object","what":"Accessing the Data","title":"Data Preprocessing","text":"","code":"# Get the processed data frame head(ts_data$data) #> # A tibble: 6 × 3 #>   date       items value #>   <date>     <fct> <dbl> #> 1 1982-04-01 V10    94   #> 2 1982-05-01 V10   106.  #> 3 1982-06-01 V10    95.1 #> 4 1982-07-01 V10    95.3 #> 5 1982-08-01 V10    82.8 #> 6 1982-09-01 V10    89.4  # Access metadata ts_data$frequency #> [1] \"month\" ts_data$groups #> [1] \"items\" ts_data$date #> [1] \"date\""},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"frequency-detection","dir":"Articles","previous_headings":"","what":"Frequency Detection","title":"Data Preprocessing","text":"TimeSeries can auto-detect frequency validate specification:","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"auto-detection","dir":"Articles","previous_headings":"Frequency Detection","what":"Auto-Detection","title":"Data Preprocessing","text":"","code":"ts_auto <- TimeSeries(   data = retail,   date = \"date\",   groups = \"items\"   # frequency not specified - will be auto-detected ) #> Auto-detected frequency: month"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"explicit-specification","dir":"Articles","previous_headings":"Frequency Detection","what":"Explicit Specification","title":"Data Preprocessing","text":"","code":"ts_explicit <- TimeSeries(   data = retail,   date = \"date\",   groups = \"items\",   frequency = \"month\" )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"completing-the-time-grid","dir":"Articles","previous_headings":"","what":"Completing the Time Grid","title":"Data Preprocessing","text":"Real data often missing dates. Use fill_time = TRUE complete calendar: happens: Rows added missing dates (2024-01-04 2024-01-07) sales NA new rows time_fill_meta tracks added","code":"# Create data with missing dates sales_irregular <- data.frame(   store = rep(\"A\", 5),   date = as.Date(c('2024-01-01', '2024-01-02', '2024-01-03',                    '2024-01-08', '2024-01-09')),  # Missing Jan 4-7   sales = c(100, 120, 110, 130, 125) )  ts_complete <- TimeSeries(   sales_irregular,   date = \"date\",   groups = \"store\",   frequency = \"day\",   fill_time = TRUE ) #> Time grid completed: 4 rows added (step size: day)  ts_complete$data #> # A tibble: 9 × 3 #>   store date       sales #>   <chr> <date>     <dbl> #> 1 A     2024-01-01   100 #> 2 A     2024-01-02   120 #> 3 A     2024-01-03   110 #> 4 A     2024-01-04    NA #> 5 A     2024-01-05    NA #> 6 A     2024-01-06    NA #> 7 A     2024-01-07    NA #> 8 A     2024-01-08   130 #> 9 A     2024-01-09   125 ts_complete$time_fill_meta #> $n_added #> [1] 4 #>  #> $n_weekends_removed #> [1] 0 #>  #> $n_net_change #> [1] 4 #>  #> $by #> [1] \"day\" #>  #> $n_total #> [1] 9"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"target-gap-filling","dir":"Articles","previous_headings":"","what":"Target Gap-Filling","title":"Data Preprocessing","text":"Fill missing values target variable using various strategies.","code":""},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"basic-usage","dir":"Articles","previous_headings":"Target Gap-Filling","what":"Basic Usage","title":"Data Preprocessing","text":"","code":"# Data with gaps sales_with_gaps <- data.frame(   date = seq(as.Date('2024-01-01'), by = 'day', length.out = 10),   sales = c(100, 120, NA, NA, 150, 160, NA, 180, 190, 200) )  ts_filled <- TimeSeries(   sales_with_gaps,   date = \"date\",   frequency = \"day\",   target = \"sales\",   target_na = list(strategy = \"locf\") ) #> Target gap-filling: 3 values imputed (30.0%) using 'locf' strategy  ts_filled$data #>          date sales sales_is_imputed #> 1  2024-01-01   100            FALSE #> 2  2024-01-02   120            FALSE #> 3  2024-01-03   120             TRUE #> 4  2024-01-04   120             TRUE #> 5  2024-01-05   150            FALSE #> 6  2024-01-06   160            FALSE #> 7  2024-01-07   160             TRUE #> 8  2024-01-08   180            FALSE #> 9  2024-01-09   190            FALSE #> 10 2024-01-10   200            FALSE"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"the-is_imputed-flag","dir":"Articles","previous_headings":"Target Gap-Filling","what":"The is_imputed Flag","title":"Data Preprocessing","text":"Every filled value tracked: Use flag : Filtering: Train real data Modeling: Use predictor (sales_is_imputed formula) Weighting: -weight imputed observations","code":"# See which values were imputed ts_filled$data %>%   select(date, sales, sales_is_imputed) #>          date sales sales_is_imputed #> 1  2024-01-01   100            FALSE #> 2  2024-01-02   120            FALSE #> 3  2024-01-03   120             TRUE #> 4  2024-01-04   120             TRUE #> 5  2024-01-05   150            FALSE #> 6  2024-01-06   160            FALSE #> 7  2024-01-07   160             TRUE #> 8  2024-01-08   180            FALSE #> 9  2024-01-09   190            FALSE #> 10 2024-01-10   200            FALSE"},{"path":[]},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"last-observation-carried-forward-locf","dir":"Articles","previous_headings":"Target Gap-Filling > Strategy Examples","what":"Last Observation Carried Forward (LOCF)","title":"Data Preprocessing","text":"Simple fast. Good sensor data short outages.","code":"ts <- TimeSeries(   data, date = \"date\", frequency = \"day\",   target = \"sales\",   target_na = list(strategy = \"locf\") )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"linear-interpolation","dir":"Articles","previous_headings":"Target Gap-Filling > Strategy Examples","what":"Linear Interpolation","title":"Data Preprocessing","text":"Smooth interpolation known values. Good slowly-changing variables.","code":"ts <- TimeSeries(   data, date = \"date\", frequency = \"day\",   target = \"sales\",   target_na = list(strategy = \"linear\") )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"seasonal-decomposition-stl","dir":"Articles","previous_headings":"Target Gap-Filling > Strategy Examples","what":"Seasonal Decomposition (STL)","title":"Data Preprocessing","text":"Uses seasonal pattern fill gaps. Best clearly seasonal data.","code":"ts <- TimeSeries(   data, date = \"date\", frequency = \"day\",   target = \"sales\",   target_na = list(     strategy = \"stl\",     params = list(period = 7)  # Weekly seasonality   ) )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"cross-series-borrowing","dir":"Articles","previous_headings":"Target Gap-Filling > Strategy Examples","what":"Cross-Series Borrowing","title":"Data Preprocessing","text":"Uses values groups date. Good cold-start problems.","code":"# For panel data: fill from peer groups ts <- TimeSeries(   panel_data,   date = \"date\",   groups = \"store\",   frequency = \"day\",   target = \"sales\",   target_na = list(     strategy = \"borrow\",     params = list(method = \"median\")  # Use median of peers   ) )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"strategy-parameters","dir":"Articles","previous_headings":"Target Gap-Filling","what":"Strategy Parameters","title":"Data Preprocessing","text":"Control gap-filling behavior: Common parameters: max_gap: Maximum consecutive NAs fill (error exceeded) period: Seasonal period STL window: Window size rolling_mean center: TRUE centered window, FALSE right-aligned","code":"ts <- TimeSeries(   data, date = \"date\", frequency = \"day\",   target = \"sales\",   target_na = list(     strategy = \"locf\",     params = list(       max_gap = 7  # Error if gap > 7 days     )   ) )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"exogenous-gap-filling","dir":"Articles","previous_headings":"","what":"Exogenous Gap-Filling","title":"Data Preprocessing","text":"Fill gaps predictor variables different strategies per column:","code":"retail_with_gaps <- data.frame(   date = seq(as.Date('2024-01-01'), by = 'day', length.out = 10),   sales = c(100, 120, 130, 140, 150, 160, 170, 180, 190, 200),   price = c(10, NA, NA, 10, 12, 12, NA, 12, 12, 12),   promo = c(0, 0, 1, 1, NA, NA, 0, 0, 0, 1),   temp = c(20, 21, NA, 23, 24, NA, 26, 27, 28, 29) )  ts_xreg <- TimeSeries(   retail_with_gaps,   date = \"date\",   frequency = \"day\",   xreg_na = list(     price = list(strategy = \"locf\"),      # Prices are sticky     promo = list(strategy = \"zero\"),      # Missing = no promotion     temp = list(strategy = \"linear\")      # Smooth weather interpolation   ) ) #> Exogenous 'price': 3 values imputed (30.0%) using 'locf' strategy #> Exogenous 'promo': 2 values imputed (20.0%) using 'zero' strategy #> Exogenous 'temp': 2 values imputed (20.0%) using 'linear' strategy  ts_xreg$data %>%   select(date, price, price_is_imputed, promo, promo_is_imputed, temp, temp_is_imputed) #>          date price price_is_imputed promo promo_is_imputed temp #> 1  2024-01-01    10            FALSE     0            FALSE   20 #> 2  2024-01-02    10             TRUE     0            FALSE   21 #> 3  2024-01-03    10             TRUE     1            FALSE   22 #> 4  2024-01-04    10            FALSE     1            FALSE   23 #> 5  2024-01-05    12            FALSE     0             TRUE   24 #> 6  2024-01-06    12            FALSE     0             TRUE   25 #> 7  2024-01-07    12             TRUE     0            FALSE   26 #> 8  2024-01-08    12            FALSE     0            FALSE   27 #> 9  2024-01-09    12            FALSE     0            FALSE   28 #> 10 2024-01-10    12            FALSE     1            FALSE   29 #>    temp_is_imputed #> 1            FALSE #> 2            FALSE #> 3             TRUE #> 4            FALSE #> 5            FALSE #> 6             TRUE #> 7            FALSE #> 8            FALSE #> 9            FALSE #> 10           FALSE"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"complete-pipeline-example","dir":"Articles","previous_headings":"","what":"Complete Pipeline Example","title":"Data Preprocessing","text":"Handle three problems one call:","code":"# Messy data: missing dates + target gaps + exogenous gaps messy_data <- data.frame(   store = rep(\"A\", 7),   date = as.Date(c('2024-01-01', '2024-01-02', '2024-01-03',                    '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09')),   sales = c(100, 120, NA, 160, 170, NA, 190),   price = c(10, 10, 10, NA, 12, 12, 12),   promo = c(0, 1, 1, NA, 0, 0, 0) )  ts_clean <- TimeSeries(   messy_data,   date = \"date\",   groups = \"store\",   frequency = \"day\",   fill_time = TRUE,   target = \"sales\",   target_na = list(strategy = \"locf\"),   xreg_na = list(     price = list(strategy = \"locf\"),     promo = list(strategy = \"zero\")   ) ) #> Time grid completed: 2 rows added (step size: day) #> Target gap-filling: 4 values imputed (44.4%) using 'locf' strategy #> Exogenous 'price': 3 values imputed (33.3%) using 'locf' strategy #> Exogenous 'promo': 3 values imputed (33.3%) using 'zero' strategy  ts_clean #> TimeSeries object #> ---------------- #> Date column: date ( Date ) #> Frequency: day  #> Groups: store  #> Observations: 9  #> Time grid: 2 rows added (step: day ) #> Target: sales [locf: 4 imputed, 44.4%] #> Exogenous: #>   price [locf: 3 imputed, 33.3%] #>   promo [zero: 3 imputed, 33.3%] #>  #> Data (first few rows): #> # A tibble: 6 × 8 #>   store date       sales price promo sales_is_imputed price_is_imputed #>   <chr> <date>     <dbl> <dbl> <dbl> <lgl>            <lgl>            #> 1 A     2024-01-01   100    10     0 FALSE            FALSE            #> 2 A     2024-01-02   120    10     1 FALSE            FALSE            #> 3 A     2024-01-03   120    10     1 TRUE             FALSE            #> 4 A     2024-01-04   120    10     0 TRUE             TRUE             #> 5 A     2024-01-05   120    10     0 TRUE             TRUE             #> 6 A     2024-01-06   160    10     0 FALSE            TRUE             #> # ℹ 1 more variable: promo_is_imputed <lgl> ts_clean$data #> # A tibble: 9 × 8 #>   store date       sales price promo sales_is_imputed price_is_imputed #>   <chr> <date>     <dbl> <dbl> <dbl> <lgl>            <lgl>            #> 1 A     2024-01-01   100    10     0 FALSE            FALSE            #> 2 A     2024-01-02   120    10     1 FALSE            FALSE            #> 3 A     2024-01-03   120    10     1 TRUE             FALSE            #> 4 A     2024-01-04   120    10     0 TRUE             TRUE             #> 5 A     2024-01-05   120    10     0 TRUE             TRUE             #> 6 A     2024-01-06   160    10     0 FALSE            TRUE             #> 7 A     2024-01-07   170    12     0 FALSE            FALSE            #> 8 A     2024-01-08   170    12     0 TRUE             FALSE            #> 9 A     2024-01-09   190    12     0 FALSE            FALSE            #> # ℹ 1 more variable: promo_is_imputed <lgl>"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"metadata-and-auditability","dir":"Articles","previous_headings":"","what":"Metadata and Auditability","title":"Data Preprocessing","text":"TimeSeries tracks preprocessing:","code":"# Time grid completion ts_clean$time_fill_meta #> $n_added #> [1] 2 #>  #> $n_weekends_removed #> [1] 0 #>  #> $n_net_change #> [1] 2 #>  #> $by #> [1] \"day\" #>  #> $n_total #> [1] 9  # Target gap-filling ts_clean$target_na_meta #> $strategy #> [1] \"locf\" #>  #> $params #> list() #>  #> $n_imputed #> [1] 4 #>  #> $n_total #> [1] 9 #>  #> $pct_imputed #> [1] 44.44444  # Exogenous gap-filling ts_clean$xreg_na_meta #> $price #> $price$strategy #> [1] \"locf\" #>  #> $price$params #> list() #>  #> $price$n_imputed #> [1] 3 #>  #> $price$n_total #> [1] 9 #>  #> $price$pct_imputed #> [1] 33.33333 #>  #>  #> $promo #> $promo$strategy #> [1] \"zero\" #>  #> $promo$params #> list() #>  #> $promo$n_imputed #> [1] 3 #>  #> $promo$n_total #> [1] 9 #>  #> $promo$pct_imputed #> [1] 33.33333"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"saving-metadata-for-reproducibility","dir":"Articles","previous_headings":"Metadata and Auditability","what":"Saving Metadata for Reproducibility","title":"Data Preprocessing","text":"","code":"# Save preprocessing configuration config <- list(   created = Sys.time(),   frequency = ts_clean$frequency,   fill_time = ts_clean$time_fill_meta,   target_na = ts_clean$target_na_meta,   xreg_na = ts_clean$xreg_na_meta )  saveRDS(config, \"preprocessing_config.rds\")"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"integration-with-fit-and-forecast","dir":"Articles","previous_headings":"","what":"Integration with fit() and forecast()","title":"Data Preprocessing","text":"fit() automatically extracts uses processed data:","code":"ts <- TimeSeries(   retail, date = \"date\", groups = \"items\",   frequency = \"month\",   target = \"value\",   target_na = list(strategy = \"locf\") )  # fit() uses ts$data automatically m <- fit(value ~ p(12) + month(), data = ts, model = lm)  # forecast() uses stored frequency for date generation fc <- forecast(m, h = 12)"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"the-is_imputed-flag-as-a-predictor","dir":"Articles","previous_headings":"Integration with fit() and forecast()","what":"The is_imputed Flag as a Predictor","title":"Data Preprocessing","text":"","code":"# Let the model know which values were imputed m <- fit(   value ~ p(12) + month() + value_is_imputed,   data = ts,   model = lm )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"weighting-by-imputation-status","dir":"Articles","previous_headings":"Integration with fit() and forecast()","what":"Weighting by Imputation Status","title":"Data Preprocessing","text":"","code":"# Down-weight imputed observations (requires custom model spec) weighted_lm_spec <- list(   fit = function(y, X, ...) {     # Check for is_imputed column     if (\"value_is_imputed\" %in% names(X)) {       weights <- ifelse(X$value_is_imputed, 0.5, 1.0)       X$value_is_imputed <- NULL  # Remove from predictors     } else {       weights <- rep(1, length(y))     }      train_df <- cbind(data.frame(.response = y), X)     lm(.response ~ ., data = train_df, weights = weights)   },   predict = function(object, newdata, ...) {     newdata$value_is_imputed <- NULL     predict(object, newdata = newdata)   } )"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"validate-preprocessing-results","dir":"Articles","previous_headings":"Best Practices","what":"1. Validate Preprocessing Results","title":"Data Preprocessing","text":"","code":"# Check imputation rates ts$data %>%   summarise(     pct_sales_imputed = 100 * mean(sales_is_imputed),     pct_price_imputed = 100 * mean(price_is_imputed)   )  # Check for remaining NAs sapply(ts$data, function(x) sum(is.na(x)))"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"use-max_gap-to-prevent-over-imputation","dir":"Articles","previous_headings":"Best Practices","what":"2. Use max_gap to Prevent Over-Imputation","title":"Data Preprocessing","text":"","code":"# Refuse to fill gaps longer than 7 days target_na = list(   strategy = \"locf\",   params = list(max_gap = 7) )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"compare-strategies","dir":"Articles","previous_headings":"Best Practices","what":"3. Compare Strategies","title":"Data Preprocessing","text":"","code":"# Test different strategies ts_locf <- TimeSeries(..., target_na = list(strategy = \"locf\")) ts_linear <- TimeSeries(..., target_na = list(strategy = \"linear\")) ts_stl <- TimeSeries(..., target_na = list(strategy = \"stl\"))  # Compare forecast accuracy with cross-validation cv_locf <- cv_forecast(value ~ p(12), data = ts_locf, model = lm, h = 6) cv_linear <- cv_forecast(value ~ p(12), data = ts_linear, model = lm, h = 6) cv_stl <- cv_forecast(value ~ p(12), data = ts_stl, model = lm, h = 6)"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"document-preprocessing-decisions","dir":"Articles","previous_headings":"Best Practices","what":"4. Document Preprocessing Decisions","title":"Data Preprocessing","text":"","code":"# Record your choices preprocessing_notes <- list(   target_strategy = \"STL with period=7\",   rationale = \"Weekly seasonality detected in autocorrelation\",   alternatives_tried = c(\"locf\", \"linear\"),   validation = \"STL gave lowest CV RMSE\" )"},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"warning-trailing-na-after-fill_time","dir":"Articles","previous_headings":"","what":"Warning: Trailing NA After fill_time","title":"Data Preprocessing","text":"fill_time = TRUE adds rows end series without target values, forecasting fail: Solution: Either specify target_na fill gaps, ensure data ends non-NA target values.","code":"# This will warn about trailing NA ts <- TimeSeries(   data_ending_mid_month,   date = \"date\",   frequency = \"day\",   fill_time = TRUE,  # Completes to end of month   target = \"sales\"   # But no target_na specified! )  # forecast() will error: \"trailing NA\""},{"path":"https://taf-society.github.io/chronofeat/articles/preprocessing.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Data Preprocessing","text":"Key outputs: $data - Processed data frame $*_is_imputed columns - Track values filled $*_meta - Metadata auditability See also: ?fill_gaps detailed strategy documentation.","code":""},{"path":"https://taf-society.github.io/chronofeat/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Resul Akay. Author, maintainer.","code":""},{"path":"https://taf-society.github.io/chronofeat/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Akay R (2026). chronofeat: Time-Based Feature Engineering Forecasting. R package version 0.6.0, https://taf-society.github.io/chronofeat/.","code":"@Manual{,   title = {chronofeat: Time-Based Feature Engineering for Forecasting},   author = {Resul Akay},   year = {2026},   note = {R package version 0.6.0},   url = {https://taf-society.github.io/chronofeat/}, }"},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"chronofeat","dir":"","previous_headings":"","what":"chronofeat","title":"chronofeat","text":"chronofeat R package time-based feature engineering forecasting. provides flexible, formula-based interface creating temporal features (lags, moving averages, rolling statistics, calendar features) works R model fit/predict interface.","code":""},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"chronofeat","text":"Formula-based feature specification: Define features using intuitive syntax like value ~ p(12) + q(7) + month() Model-agnostic: Works lm, glm, xgboost, lightgbm, randomForest, custom model Recursive multi-step forecasting: Automatically generates features forecast step Panel data support: Handle multiple time series proper group boundaries C++ acceleration: Fast recursive forecasting via cpp11","code":""},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"about-tafs","dir":"","previous_headings":"","what":"About TAFS","title":"chronofeat","text":"TAFS (Time Series Analysis Forecasting Society) non-profit association (“Verein”) Vienna, Austria. connects academics, experts, practitioners, students focused time-series, forecasting, decision science. Contributions remain fully open source. Learn taf-society.org.","code":""},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"chronofeat","text":"development version GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"taf-society/chronofeat\")"},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"chronofeat","text":"","code":"library(chronofeat)  # Load sample data data(retail)  # Create TimeSeries object ts_data <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")  # Fit a model with formula-based features model <- fit(   value ~ p(12) + q(7, 12) + month(),   data = ts_data,   model = lm )  # Generate forecasts forecasts <- forecast(model, h = 6)"},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"chronofeat","text":"Visit package website : Getting Started Building Custom Models Feature Engineering Reference Cross-Validation","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"function creates TimeSeries object bundles data frequency information provides comprehensive preprocessing pipeline time series data. handles: Frequency detection validation Irregular calendar completion (missing dates) Target variable gap-filling Exogenous variable gap-filling","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"","code":"TimeSeries(   data,   date,   groups = NULL,   frequency = NULL,   auto_detect = TRUE,   target = NULL,   target_na = NULL,   fill_time = FALSE,   xreg_na = NULL )"},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"data data frame containing time series data date Character string naming date column. Accepts: Date: daily longer frequencies (day, week, month, quarter, year) POSIXct: Required sub-daily frequencies (second, minute, halfhour, hour) groups Optional character vector naming grouping columns panel data. preprocessing operations (time grid completion, gap-filling) performed independently per group. frequency Character string numeric specifying time frequency: Sub-daily (require POSIXct): \"second\", \"minute\", \"halfhour\", \"hour\" Daily+ (work Date POSIXct): \"day\", \"businessday\", \"biweekly\", \"week\", \"month\", \"quarter\", \"year\" Numeric: Custom interval days (e.g., 7 weekly, 14 biweekly) NULL auto_detect = TRUE, frequency inferred median date/time differences. auto_detect Logical, TRUE frequency NULL, attempt detect frequency data. Default: TRUE. target Character string naming target column (optional). Required target_na specified. target column gap-filled according target_na strategy. target_na List specifying gap-filling strategy missing target values. strategy: Character, one : \"error\" - Fail NAs present (forces explicit choice) \"zero\" - Replace NAs 0 (useful count data) \"locf\" - Last observation carried forward \"nocb\" - Next observation carried backward \"linear\" - Linear interpolation (time-aware) \"rolling_mean\" - Centered right-aligned rolling mean \"stl\" - Seasonal-Trend-Loess decomposition (auto-detects period) \"borrow\" - Cross-series borrowing peer groups \"custom\" - User-provided function params: List strategy-specific parameters (see Details) Default: NULL (target gap-filling). Adds {target}_is_imputed flag column. fill_time Logical, TRUE, complete missing dates using tidyr::complete(). Uses frequency parameter determine step size. enabled, adds rows missing dates NA values dynamic columns. Respects group boundaries panel data. Default: FALSE. xreg_na Named list specifying gap-filling strategies exogenous columns. element : column_name = list(strategy = \"...\", params = list(...)). Keys: Column names fill (must exist data) Values: Lists strategy params (target_na) Example: list(price = list(strategy = \"locf\"), promo = list(strategy = \"zero\")). column gets {column}_is_imputed flag. Filling done per-group groups specified.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"TimeSeries object (S3 class) components: data - Data frame completed calendar filled gaps (requested) date - Name date column groups - Names grouping columns (NULL) frequency - Time frequency specification target - Name target column (NULL) target_na_meta - Metadata target gap-filling (NULL): strategy - Strategy used params - Parameters used n_imputed - Number values imputed n_total - Total observations pct_imputed - Percentage imputed xreg_na_meta - Named list metadata exogenous column (empty list) time_fill_meta - Metadata time grid completion (NULL): n_added - Number rows added - Step size used n_total - Total observations completion","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"preprocessing auditable via metadata is_imputed flags.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"preprocessing-pipeline-order","dir":"Reference","previous_headings":"","what":"Preprocessing Pipeline Order","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"TimeSeries() applies preprocessing order: Sort data groups (present) date Complete time grid (fill_time$enabled = TRUE) Per-group panel data Adds rows missing dates NA values Fill target (target target_na specified) Uses specified strategy Adds {target}_is_imputed flag Fill exogenous columns (xreg_na specified) Per-column, per-group filling Adds {column}_is_imputed flag ","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"gap-filling-strategy-parameters","dir":"Reference","previous_headings":"","what":"Gap-Filling Strategy Parameters","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"Common parameters across strategies: max_gap: Maximum consecutive NAs fill (default: Inf). Throws error gap exceeds value. Strategy-specific parameters: linear: extrapolate = FALSE - Allow extrapolation beyond observed range rolling_mean: window = 7, center = TRUE - Window size alignment stl: period = NULL, robust = TRUE - Seasonal period (auto-detected NULL) robust fitting borrow: method = \"median\", neighbors = NULL - Aggregation method neighbor filtering custom: fn = function(y, dates, params) {...} - User-provided function See ?fill_gaps detailed documentation strategy.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"auditability","dir":"Reference","previous_headings":"","what":"Auditability","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"gap-filling operations add is_imputed flags: {target}_is_imputed - Logical vector marking imputed target values {column}_is_imputed - Logical vector exogenous column flags can used : Filter imputed rows: data[!data$sales_is_imputed, ] Use model predictor: sales ~ ... + sales_is_imputed Weight observations: lm(..., weights = ifelse(is_imputed, 0.5, 1)) Metadata stored TimeSeries object full reproducibility.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/TimeSeries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a TimeSeries Object with Complete Preprocessing Pipeline — TimeSeries","text":"","code":"if (FALSE) { # \\dontrun{ # ===== Basic Usage ===== # Create TimeSeries with auto-detected frequency ts <- TimeSeries(retail, date = \"date\", groups = \"store\")  # Specify frequency explicitly ts <- TimeSeries(retail, date = \"date\", groups = \"store\", frequency = \"day\")  # ===== Target Gap-Filling ===== # Fill target with last observation carried forward ts <- TimeSeries(   retail,   date = \"date\",   target = \"sales\",   target_na = list(strategy = \"locf\", params = list(max_gap = 7)) )  # Fill target with seasonal decomposition ts <- TimeSeries(   retail,   date = \"date\",   groups = \"store\",   target = \"sales\",   target_na = list(strategy = \"stl\", params = list(period = 7)) )  # ===== Complete Preprocessing Pipeline ===== # Handle irregular calendar + target gaps + exogenous gaps ts <- TimeSeries(   sales_df,   date = \"date\",   groups = c(\"store\", \"item\"),   frequency = \"day\",   target = \"sales\",   target_na = list(strategy = \"locf\"),   fill_time = TRUE,  # Complete missing dates using frequency   xreg_na = list(     price = list(strategy = \"linear\"),  # Smooth interpolation     promo = list(strategy = \"zero\")     # NA = no promotion   ) )  # Inspect preprocessing results print(ts)  # Shows all metadata summary(ts$data$sales_is_imputed)  # Check how many values imputed  # ===== Using with fit() and forecast() ===== # fit() extracts cleaned data automatically m <- fit(sales ~ p(7) + price + promo, data = ts, model = lm)  # forecast() uses stored frequency fc <- forecast(m, h = 14)  # ===== Panel Data Example ===== # Each store gets independent preprocessing ts <- TimeSeries(   panel_df,   date = \"date\",   groups = \"store\",   frequency = \"day\",   target = \"sales\",   target_na = list(strategy = \"borrow\", params = list(method = \"median\")),   fill_time = TRUE,  # Uses frequency = \"day\"   xreg_na = list(     price = list(strategy = \"locf\"),     temp = list(strategy = \"linear\")   ) )  # Metadata shows per-store/column imputation counts ts$time_fill_meta  # Rows added to complete calendar ts$target_na_meta  # Target imputation stats ts$xreg_na_meta    # Exogenous imputation stats per column } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Model Function to Model Specification — as_model_spec","title":"Convert Model Function to Model Specification — as_model_spec","text":"Converts model function (e.g., lm, glm) model specification list fit predict functions compatible chronofeat API.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Model Function to Model Specification — as_model_spec","text":"","code":"as_model_spec(model_fn, ...)"},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Model Function to Model Specification — as_model_spec","text":"model_fn model function accepts formula data argument ... Additional arguments passed model function fitting","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Model Function to Model Specification — as_model_spec","text":"list fit predict functions: fit(y, X, ...) - Fits model response y predictors X predict(object, newdata, ...) - Generates predictions fitted model","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Model Function to Model Specification — as_model_spec","text":"function provides backward compatibility users want pass model functions directly (e.g., model = lm) instead model specifications. wrapper creates formula-based interface internally, combining y X temporary data frame fitting model using standard R formula interface. Supported model functions include accept standard formula/data interface: lm, glm, randomForest::randomForest, ranger::ranger, etc.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/as_model_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Model Function to Model Specification — as_model_spec","text":"","code":"if (FALSE) { # \\dontrun{ # Convert lm to model spec lm_spec <- as_model_spec(lm)  # Convert glm with family argument glm_spec <- as_model_spec(glm, family = poisson())  # Use directly in fit() m <- fit(value ~ p(12), data = df, date = \"date\", model = lm) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat-package.html","id":null,"dir":"Reference","previous_headings":"","what":"chronofeat: Time-Based Feature Engineering for Forecasting — chronofeat-package","title":"chronofeat: Time-Based Feature Engineering for Forecasting — chronofeat-package","text":"flexible, formula-based interface time series feature engineering forecasting. Automatically generates temporal features (lags, moving averages, rolling statistics, calendar features) concise formula specification. Model-agnostic: works R model accepts fit/predict interface. Supports multi-group panel data recursive multi-step prediction.","code":""},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"chronofeat: Time-Based Feature Engineering for Forecasting — chronofeat-package","text":"Maintainer: Resul Akay resul.akay@quantics.io","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":null,"dir":"Reference","previous_headings":"","what":"chronofeat Package Overview — chronofeat","title":"chronofeat Package Overview — chronofeat","text":"chronofeat package provides formula-based interface time series feature engineering forecasting. handles lag creation, moving averages, rolling statistics, calendar features, recursive multi-step ahead forecasting.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main Functions","title":"chronofeat Package Overview — chronofeat","text":"TimeSeries Create TimeSeries object explicit frequency fit Fit forecasting model automatic feature engineering forecast Generate recursive multi-step ahead forecasts cv_forecast Time series cross-validation","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":"key-features","dir":"Reference","previous_headings":"","what":"Key Features","title":"chronofeat Package Overview — chronofeat","text":"Automatic Feature Engineering: Lags: p(k) creates k lags target variable Moving Averages: q(w1, w2) creates MAs specified windows Rolling Statistics: rollsum(), rollsd(), rollmin(), rollmax(), rollslope() Calendar Features: dow(), month(), woy(), eom(), dom() Trend Features: trend(1, 2, 3) polynomial trends Exogenous Variables: lag(varname, k1, k2), ma(varname, w1, w2) Recursive Forecasting: Multi-step ahead forecasts generated recursively, predictions previous steps feed back inputs future steps. standard approach autoregressive models. Stable Date Generation: Use TimeSeries objects store frequency information explicitly, ensuring stable predictable future date generation using R's seq.Date() instead median-based inference. Model Agnostic: Works model can expressed list fit(y, X) predict(object, newdata) functions. Simply provide model :","code":"model <- list(   fit = function(y, X, ...) { ... },   predict = function(object, newdata, ...) { ... } )"},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":"important-edge-cases","dir":"Reference","previous_headings":"","what":"Important Edge Cases","title":"chronofeat Package Overview — chronofeat","text":"Incomplete Windows: forecasting, window size exceeds available history (actual + previous predictions), rolling statistics moving averages return NA match training behavior. Factor Levels: Factor levels observed training stored model schema. Unknown levels forecast data converted NA warning. Data Sorting: TimeSeries objects automatically sort data groups date. using plain data frames, ensure data pre-sorted avoid incorrect lag calculations. Minimum Data Requirements: Lags: Need least p observations per group Moving Averages: Need least max(q) observations Frequency Detection: Need least 2 date observations per group","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":"getting-started","dir":"Reference","previous_headings":"","what":"Getting Started","title":"chronofeat Package Overview — chronofeat","text":"","code":"library(chronofeat)  # Define your model my_model <- list(   fit = function(y, X, ...) lm.fit(as.matrix(cbind(1, X)), y),   predict = function(object, newdata, ...) {     as.numeric(cbind(1, as.matrix(newdata))    } )  # Create TimeSeries with frequency ts_data <- TimeSeries(data, date = \"date\", groups = \"items\", frequency = \"month\")  # Fit model with automatic feature engineering m <- fit(value ~ p(12) + q(7, 28) + month() + dow(),          data = ts_data,          model = my_model)  # Generate 24-step ahead forecast fc <- forecast(m, h = 24)  # Cross-validation cv_results <- cv_forecast(   value ~ p(12) + month(),   data = ts_data,   model = my_model,   h = 6,   n_windows = 5 )"},{"path":"https://taf-society.github.io/chronofeat/reference/chronofeat.html","id":"learn-more","dir":"Reference","previous_headings":"","what":"Learn More","title":"chronofeat Package Overview — chronofeat","text":"vignette(\"feature-engineering--forecasting\") - Comprehensive guide vignette(\"edge-cases--best-practices\") - Edge cases best practices ?fit - Detailed documentation model fitting ?forecast - Detailed documentation forecasting ?TimeSeries - Information TimeSeries objects","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Time Series Cross-Validation — cv_forecast","title":"Time Series Cross-Validation — cv_forecast","text":"Perform time series cross-validation using expanding sliding windows. Evaluates forecast accuracy across multiple time periods assess model performance tune hyperparameters.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time Series Cross-Validation — cv_forecast","text":"","code":"cv_forecast(   formula,   data,   date = NULL,   groups = NULL,   model,   h = 1,   n_windows = 5,   window_type = c(\"expanding\", \"sliding\"),   window_size = NULL,   step_size = NULL,   metric = \"rmse\",   return_predictions = FALSE,   ... )"},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time Series Cross-Validation — cv_forecast","text":"formula formula specifying target features (fit()) data data frame TimeSeries object containing time series data date Character string naming date column (Date POSIXct class). Optional data TimeSeries object (uses stored date column). groups Character vector naming grouping columns panel data model Model specification (fit()) h Forecast horizon (number periods ahead forecast) n_windows Number cross-validation folds/windows window_type Type training window: \"expanding\" (default) \"sliding\" window_size Size training window sliding window (ignored expanding) step_size Number periods step forward folds (default: h) metric Evaluation metric: \"rmse\", \"mae\", \"mape\", custom function return_predictions Logical, whether return individual predictions (default: FALSE) ... Additional arguments passed model's fit function","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time Series Cross-Validation — cv_forecast","text":"list containing: metrics - Data frame metrics per fold overall predictions - Data frame predictions (return_predictions = TRUE) params - List CV parameters used","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time Series Cross-Validation — cv_forecast","text":"function performs time series cross-validation : Splitting data multiple train/test windows Fitting model training window Generating h-step ahead forecasts test window Computing specified metrics fold Expanding window: Training set grows fold (recommended cases) Sliding window: Training set fixed size, slides forward","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/cv_forecast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time Series Cross-Validation — cv_forecast","text":"","code":"if (FALSE) { # \\dontrun{ # Basic CV with expanding window cv_results <- cv_forecast(   value ~ p(12) + month(),   data = retail,   date = \"date\",   groups = \"items\",   model = lm,   h = 6,   n_windows = 5 ) print(cv_results$metrics)  # CV with custom model specification custom_model <- list(   fit = function(y, X, ...) {     train_df <- cbind(data.frame(.response = y), X)     lm(.response ~ ., data = train_df)   },   predict = function(object, newdata, ...) {     stats::predict(object, newdata = newdata)   } ) cv_results <- cv_forecast(   value ~ p(12) + trend() + rollsum(7, 28),   data = retail,   date = \"date\",   groups = \"items\",   model = custom_model,   h = 12,   n_windows = 5,   metric = \"rmse\" )  # Sliding window CV cv_results <- cv_forecast(   value ~ p(6) + month(),   data = retail,   date = \"date\",   groups = \"items\",   model = lm,   h = 3,   n_windows = 10,   window_type = \"sliding\",   window_size = 120 ) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-apply_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Schema and Predictor Selection — .apply_schema","title":"Apply Schema and Predictor Selection — .apply_schema","text":"Harmonizes prediction row match training schema selects predictors needed model.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-apply_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Schema and Predictor Selection — .apply_schema","text":"","code":".apply_schema(new_row, schema = NULL, predictors = NULL)"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-apply_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Schema and Predictor Selection — .apply_schema","text":"new_row Single-row tibble raw features schema Named list column types training (NULL skip) predictors Character vector predictor names (NULL skip)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-apply_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Schema and Predictor Selection — .apply_schema","text":"Single-row tibble, harmonized filtered","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-build_future_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Build Future Date Grid — .build_future_grid","title":"Build Future Date Grid — .build_future_grid","text":"Generates future dates forecasting, handling single-series grouped data. grouped data, creates cross-product groups x future dates.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-build_future_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build Future Date Grid — .build_future_grid","text":"","code":".build_future_grid(history, h, date_col, groups_chr = NULL, frequency = NULL)"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-build_future_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build Future Date Grid — .build_future_grid","text":"history Data frame historical data h Integer, forecast horizon date_col Character, name date column groups_chr Character vector group column names (NULL ungrouped) frequency Frequency object date generation","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-build_future_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build Future Date Grid — .build_future_grid","text":"Tibble future dates (group keys grouped)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-check_trailing_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for Trailing NA Targets — .check_trailing_na","title":"Check for Trailing NA Targets — .check_trailing_na","text":"Validates target column end NA values sorting date. Trailing NAs cause lags target-based features produce NA values, leads NA forecasts.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-check_trailing_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for Trailing NA Targets — .check_trailing_na","text":"","code":".check_trailing_na(data, target_col, groups_chr = NULL)"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-check_trailing_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for Trailing NA Targets — .check_trailing_na","text":"data Data frame history, already sorted groups date target_col Character, name target column groups_chr Character vector group column names (NULL ungrouped)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-check_trailing_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for Trailing NA Targets — .check_trailing_na","text":"NULL (invisibly). Stops error trailing NAs found.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_borrow_grouped.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Series Borrowing (Grouped Data) — .fill_borrow_grouped","title":"Cross-Series Borrowing (Grouped Data) — .fill_borrow_grouped","text":"Fill NAs one series borrowing similar peer series.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_borrow_grouped.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Series Borrowing (Grouped Data) — .fill_borrow_grouped","text":"","code":".fill_borrow_grouped(data, target_col, date_col, groups_chr, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_borrow_grouped.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Series Borrowing (Grouped Data) — .fill_borrow_grouped","text":"data Full data frame groups target_col Character, name target column date_col Character, name date column groups_chr Character vector group column names params List : method: \"median\" (default), \"mean\", \"weighted\" neighbors: NULL (groups), character vector (single group column), named list (multi-level groups, e.g., list(region = c(\"North\", \"South\"))) max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_borrow_grouped.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Series Borrowing (Grouped Data) — .fill_borrow_grouped","text":"Data frame filled target column","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_custom.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom User Function — .fill_custom","title":"Custom User Function — .fill_custom","text":"Apply user-provided filling function.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_custom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom User Function — .fill_custom","text":"","code":".fill_custom(y, dates, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_custom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom User Function — .fill_custom","text":"y Numeric vector dates Date vector params List : fn: User function signature fn(y, dates, params)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_custom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom User Function — .fill_custom","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Interpolation — .fill_linear","title":"Linear Interpolation — .fill_linear","text":"Fill NAs using linear interpolation known points.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Interpolation — .fill_linear","text":"","code":".fill_linear(y, dates, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Interpolation — .fill_linear","text":"y Numeric vector dates Date vector params List : extrapolate: Allow extrapolation beyond known range (default: FALSE) max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Interpolation — .fill_linear","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_locf.html","id":null,"dir":"Reference","previous_headings":"","what":"Last Observation Carried Forward (LOCF) — .fill_locf","title":"Last Observation Carried Forward (LOCF) — .fill_locf","text":"Fill NAs carrying forward last non-NA value.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_locf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Last Observation Carried Forward (LOCF) — .fill_locf","text":"","code":".fill_locf(y, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_locf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Last Observation Carried Forward (LOCF) — .fill_locf","text":"y Numeric vector params List : max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_locf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Last Observation Carried Forward (LOCF) — .fill_locf","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_nocb.html","id":null,"dir":"Reference","previous_headings":"","what":"Next Observation Carried Backward (NOCB) — .fill_nocb","title":"Next Observation Carried Backward (NOCB) — .fill_nocb","text":"Fill NAs carrying backward next non-NA value.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_nocb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Next Observation Carried Backward (NOCB) — .fill_nocb","text":"","code":".fill_nocb(y, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_nocb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Next Observation Carried Backward (NOCB) — .fill_nocb","text":"y Numeric vector params List : max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_nocb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Next Observation Carried Backward (NOCB) — .fill_nocb","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_rolling_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Rolling Mean Imputation — .fill_rolling_mean","title":"Rolling Mean Imputation — .fill_rolling_mean","text":"Fill NAs using centered rolling mean nearby observations.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_rolling_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rolling Mean Imputation — .fill_rolling_mean","text":"","code":".fill_rolling_mean(y, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_rolling_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rolling Mean Imputation — .fill_rolling_mean","text":"y Numeric vector params List : window: Window size (default: 7) center: Center window (default: TRUE) max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_rolling_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rolling Mean Imputation — .fill_rolling_mean","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_single_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill Single Time Series — .fill_single_series","title":"Fill Single Time Series — .fill_single_series","text":"Apply gap-filling strategy single time series.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_single_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill Single Time Series — .fill_single_series","text":"","code":".fill_single_series(y, dates, strategy, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_single_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill Single Time Series — .fill_single_series","text":"y Numeric vector potential NAs dates Date vector (length y) strategy Character, gap-filling strategy params List strategy-specific parameters","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_single_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill Single Time Series — .fill_single_series","text":"List : values: Numeric vector (filled) is_imputed: Logical vector indicating imputed positions","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_stl.html","id":null,"dir":"Reference","previous_headings":"","what":"STL Decomposition Imputation — .fill_stl","title":"STL Decomposition Imputation — .fill_stl","text":"Fill NAs using seasonal decomposition fitted values.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_stl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"STL Decomposition Imputation — .fill_stl","text":"","code":".fill_stl(y, dates, params = list())"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_stl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"STL Decomposition Imputation — .fill_stl","text":"y Numeric vector dates Date vector params List : period: Seasonal period (NULL = auto-detect, e.g., 7 weekly, 365 yearly) robust: Use robust fitting (default: TRUE) max_gap: Maximum gap length fill (default: Inf)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_stl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"STL Decomposition Imputation — .fill_stl","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_target_gaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Gap-Filling Dispatcher (Internal) — .fill_target_gaps","title":"Gap-Filling Dispatcher (Internal) — .fill_target_gaps","text":"Fill missing target values using specified strategy.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_target_gaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gap-Filling Dispatcher (Internal) — .fill_target_gaps","text":"","code":".fill_target_gaps(   data,   target_col,   date_col,   groups_chr = NULL,   strategy = \"error\",   params = list() )"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_target_gaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gap-Filling Dispatcher (Internal) — .fill_target_gaps","text":"data Data frame time series data target_col Character, name target column date_col Character, name date column groups_chr Character vector group column names (NULL ungrouped) strategy Character, one : \"error\", \"zero\", \"locf\", \"nocb\", \"linear\", \"rolling_mean\", \"stl\", \"borrow\", \"custom\" params List strategy-specific parameters","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_target_gaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gap-Filling Dispatcher (Internal) — .fill_target_gaps","text":"Data frame filled target is_imputed flag column","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_zero.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero-Fill Strategy — .fill_zero","title":"Zero-Fill Strategy — .fill_zero","text":"Replace NAs 0. Appropriate count data missing = events.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_zero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero-Fill Strategy — .fill_zero","text":"","code":".fill_zero(y)"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_zero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero-Fill Strategy — .fill_zero","text":"y Numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-fill_zero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero-Fill Strategy — .fill_zero","text":"Filled numeric vector","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-prepare_feature_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare Single Prediction Row — .prepare_feature_row","title":"Prepare Single Prediction Row — .prepare_feature_row","text":"Assembles features single forecast step combining target-based features (lags, MAs, rolling stats) calendar exogenous variable features.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-prepare_feature_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare Single Prediction Row — .prepare_feature_row","text":"","code":".prepare_feature_row(   y_hist,   next_date,   target_col,   p = NULL,   q = NULL,   roll_windows = NULL,   roll_stats = c(\"sum\", \"sd\", \"min\", \"max\"),   trend_windows = NULL,   trend_degrees = NULL,   CAL_row = NULL,   XF_row = NULL,   groups_chr = NULL,   date_col = \"date\" )"},{"path":"https://taf-society.github.io/chronofeat/reference/dot-prepare_feature_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare Single Prediction Row — .prepare_feature_row","text":"y_hist Numeric vector historical target values next_date Date forecast step (used calendar/xreg lookup) target_col Character, name target column p Integer, number lags (NULL none) q Integer vector MA windows (NULL none) roll_windows Integer vector rolling stat windows (NULL none) roll_stats Character vector rolling statistics compute trend_windows Integer vector trend slopes (NULL none) trend_degrees Integer vector polynomial trends (NULL none) CAL_row Single-row tibble calendar features date (NULL none) XF_row Single-row tibble xreg features date (NULL none) groups_chr Character vector group column names (NULL ungrouped) date_col Character, name date column","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/dot-prepare_feature_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare Single Prediction Row — .prepare_feature_row","text":"Single-row tibble features","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_calendar_dt.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Calendar Features — feat_calendar_dt","title":"Add Calendar Features — feat_calendar_dt","text":"Add calendar-based features day week, month, week year, etc. features commonly useful capturing seasonal patterns time series.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_calendar_dt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Calendar Features — feat_calendar_dt","text":"","code":"feat_calendar_dt(   df,   date,   dow = TRUE,   woy = FALSE,   month = TRUE,   eom = TRUE,   dom = FALSE,   hod = FALSE,   moh = FALSE )"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_calendar_dt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Calendar Features — feat_calendar_dt","text":"df data frame containing time series data date Symbol character naming date column (Date POSIXct class) dow Logical, add day week ordered factor (1=Monday, 7=Sunday) woy Logical, add week year (1-53) month Logical, add month factor (01-12) eom Logical, add end--month indicator (0 1) dom Logical, add day month (1-31) hod Logical, add hour day (0-23) - requires POSIXct moh Logical, add minute hour (0-59) - requires POSIXct","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_calendar_dt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Calendar Features — feat_calendar_dt","text":"Data frame calendar features added","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_calendar_dt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Calendar Features — feat_calendar_dt","text":"","code":"if (FALSE) { # \\dontrun{ # Add default calendar features (dow, month, eom) df_cal <- feat_calendar_dt(df, date = date)  # Add all calendar features df_cal <- feat_calendar_dt(df, date = date,                             dow = TRUE, woy = TRUE, month = TRUE,                             eom = TRUE, dom = TRUE)  # Add sub-daily features for POSIXct data df_cal <- feat_calendar_dt(df, date = datetime, hod = TRUE, moh = TRUE) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Lag and Moving Average Features — feat_lag_ma_dt","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"Add lagged moving average features target exogenous variables. function creates features suitable time series modeling computing lags rolling averages within groups.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"","code":"feat_lag_ma_dt(   df,   date,   target,   p = NULL,   q = NULL,   groups = NULL,   xreg = NULL,   xreg_lags = NULL,   xreg_ma = NULL )"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"df data frame containing time series data date Character string naming date column target Character string naming target variable column p Integer, number target lags create (e.g., p=12 creates lag_1 lag_12) q Integer vector, moving average window sizes target (e.g., q=c(7,28)) groups Character vector naming grouping columns (e.g., c(\"store\", \"item\")) xreg Character vector naming exogenous variable columns transform xreg_lags Named list lag specifications exogenous variables (e.g., list(price = c(1,7), promotion = c(0,1))) xreg_ma Named list MA window specifications exogenous variables (e.g., list(price = c(7,28)))","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"Data frame original columns plus new lag MA features","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"Lags MAs computed within group separately. data automatically sorted groups date computation. Use lag 0 xreg_lags include current value exogenous variable.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_lag_ma_dt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Lag and Moving Average Features — feat_lag_ma_dt","text":"","code":"if (FALSE) { # \\dontrun{ # Create 7 lags and 7-day MA for sales df_feat <- feat_lag_ma_dt(df, date = \"date\", target = \"sales\",                            p = 7, q = 7, groups = \"store_id\")  # Add exogenous variable features df_feat <- feat_lag_ma_dt(df, date = \"date\", target = \"sales\",                            p = 3, groups = \"store_id\",                            xreg = \"price\",                            xreg_lags = list(price = c(0, 1, 7))) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Rolling Window Statistics — feat_rolling_dt","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"Compute rolling window statistics (sum, standard deviation, min, max) rolling trend slopes target variable. statistics computed within groups specified.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"","code":"feat_rolling_dt(   df,   date,   target,   groups = NULL,   windows = c(7, 28),   stats = c(\"sum\", \"sd\", \"min\", \"max\"),   trend_windows = NULL )"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"df data frame containing time series data date Symbol character naming date column target Symbol character naming target variable column groups Character vector naming grouping columns windows Integer vector window sizes rolling statistics (e.g., c(7, 28, 90)) stats Character vector specifying statistics compute: \"sum\", \"sd\", \"min\", \"max\" trend_windows Integer vector window sizes rolling linear trend slopes","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"Data frame rolling statistic features added","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"Rolling statistics use right-aligned windows (including current observation). Trend slopes computed fitting y ~ x within window. Missing values handled na.rm = TRUE statistics.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_rolling_dt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Rolling Window Statistics — feat_rolling_dt","text":"","code":"if (FALSE) { # \\dontrun{ # Add 7-day and 28-day rolling statistics df_roll <- feat_rolling_dt(df, date = date, target = sales,                             groups = \"store_id\",                             windows = c(7, 28),                             stats = c(\"sum\", \"sd\", \"min\", \"max\"))  # Add rolling trend slopes df_roll <- feat_rolling_dt(df, date = date, target = sales,                             groups = \"store_id\",                             windows = c(7, 28),                             stats = \"sum\",                             trend_windows = c(7, 14)) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Trend Features — feat_trend","title":"Add Trend Features — feat_trend","text":"Generate polynomial trend features time series data. Trends computed sequential indices within group, optional polynomial transformations.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Trend Features — feat_trend","text":"","code":"feat_trend(df, date, groups = NULL, degrees = 1L)"},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Trend Features — feat_trend","text":"df data frame containing time series data date Symbol character naming date column (used sorting) groups Character vector naming grouping columns degrees Integer vector polynomial degrees (e.g., c(1, 2) linear quadratic)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Trend Features — feat_trend","text":"Data frame trend features added","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Trend Features — feat_trend","text":"Trend features sequential indices (1, 2, 3, ...) within group. Polynomial degrees allow capturing non-linear trends: degree 1: linear trend (1, 2, 3, ...) degree 2: quadratic trend (1, 4, 9, ...) degree 3: cubic trend (1, 8, 27, ...)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/feat_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Trend Features — feat_trend","text":"","code":"if (FALSE) { # \\dontrun{ # Add linear trend df_trend <- feat_trend(df, date = date, groups = \"store_id\", degrees = 1)  # Add linear and quadratic trends df_trend <- feat_trend(df, date = date, groups = \"store_id\", degrees = c(1, 2)) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill Missing Target Values with Configurable Strategies — fill_gaps","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"Apply gap-filling strategies handle missing target values time series data. ensures train/forecast parity making features deterministic auditable.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"","code":"fill_gaps(   data,   target,   date,   groups = NULL,   strategy = \"error\",   params = list() )"},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"data Data frame time series data target Character, name target column date Character, name date column groups Character vector group column names (NULL ungrouped) strategy Character, gap-filling strategy. One : \"error\" - Fail NAs present (default, forces explicit choice) \"zero\" - Replace NAs 0 (appropriate count data) \"locf\" - Last observation carried forward \"nocb\" - Next observation carried backward \"linear\" - Linear interpolation (Phase 2) \"rolling_mean\" - Centered rolling mean (Phase 2) \"stl\" - Seasonal decomposition (Phase 3) \"borrow\" - Cross-series borrowing panel data (Phase 3) \"custom\" - User-provided function (Phase 4) params List strategy-specific parameters. Common parameters: max_gap - Maximum gap length fill (locf, nocb) extrapolate - Allow extrapolation (linear) window - Window size (rolling_mean) period - Seasonal period (stl) fn - User function (custom)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"Data frame : Original columns Filled target column {target}_is_imputed - Logical flag indicating imputed values","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"is_imputed flag allows downstream models : Filter imputed rows desired Use flag predictor learn different behavior Weight imputed observations differently Gap-filling respects group boundaries never fills across groups. group's time series filled independently.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fill_gaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill Missing Target Values with Configurable Strategies — fill_gaps","text":"","code":"if (FALSE) { # \\dontrun{ # Retail sales: missing = no sale sales_filled <- fill_gaps(sales_data, target = \"revenue\", date = \"date\",                           groups = \"store\", strategy = \"zero\")  # Sensor data: carry forward up to 3 missing readings sensor_filled <- fill_gaps(sensor_data, target = \"temperature\",                            date = \"timestamp\", groups = \"device\",                            strategy = \"locf\",                            params = list(max_gap = 3))  # Check imputation summary table(sensor_filled$temperature_is_imputed)  # Use filled data in forecasting ts <- TimeSeries(sensor_filled, date = \"timestamp\", groups = \"device\") m <- fit(temperature ~ p(7) + rollsum(7), data = ts, model = lm) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Time Series Forecasting Model with Formula Interface — fit","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"Train forecasting model using formula-based feature specification. function automatically generates time series features (lags, MAs, rolling stats, calendar features) formula fits specified model.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"","code":"fit(formula, data, date = NULL, groups = NULL, model, ...)"},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"formula formula specifying target features using special syntax: p(k) - Create k lags target (e.g., p(12)) q(w1, w2, ...) - Create moving averages specified windows (e.g., q(7,28)) dow(), month(), woy(), eom(), dom() - Calendar features rollsum(w1,w2), rollsd(w), rollmin(w), rollmax(w) - Rolling statistics rollslope(w) - Rolling trend slopes lag(varname, k1, k2, ...) - Lags exogenous variables ma(varname, w1, w2, ...) - MAs exogenous variables Raw column names direct inclusion data data frame TimeSeries object containing time series data date Character string naming date column (Date class required) groups Character vector naming grouping columns panel data model Model specification list fit predict functions, model function (backward compatibility, e.g., lm, glm). fit(y, X, ...) - Function fits model y (response) X (predictors matrix) predict(object, newdata, ...) - Function predicts fitted model ... Additional arguments passed model$fit function","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"tsfeature_fit object containing: model - fitted model object data - Training data features history_raw - Raw historical data forecasting formula - Expanded formula used modeling spec - Feature specifications meta - Metadata (date, groups) predictors - Predictor column names schema - Predictor schema type consistency","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"function automatically: Parses formula identify feature specifications Generates requested features within groups Removes rows NA values features (due lagging/rolling) Fits model feature-engineered data Stores necessary metadata forecasting","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"edge-cases-and-important-behaviors","dir":"Reference","previous_headings":"","what":"Edge Cases and Important Behaviors","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"Data Sorting: using TimeSeries object, data automatically sorted groups date. ensures correct lag difference calculations. passing plain data frame, ensure pre-sorted groups () date. Minimum Data Requirements: Lags: history length < lag number, lag feature NA Moving averages: history length < window size, returns NA Rolling statistics: Computed available data (see ) Frequency detection: Requires least 2 date observations per group Factor Variables: Factor levels observed training stored model schema. forecasting, new factor levels appear seen training, silently converted NA. Consider using categorical features like day--week month.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Time Series Forecasting Model with Formula Interface — fit","text":"","code":"if (FALSE) { # \\dontrun{ # Load retail data load(\"data/retail.rda\")  # Simple model with 12 lags using linear regression m1 <- fit(value ~ p(12), data = retail,           date = \"date\", groups = \"items\", model = lm)  # Model with lags, MAs, and calendar features m2 <- fit(value ~ p(12) + q(7, 28) + month() + dow(),           data = retail, date = \"date\", groups = \"items\", model = lm)  # GLM for count data m3 <- fit(count ~ p(7) + dow(), data = count_data,           date = \"date\", groups = \"store\",           model = glm, family = poisson())  # Custom model specification custom_model <- list(   fit = function(y, X, ...) {     # Your custom fitting logic     train_df <- cbind(data.frame(.response = y), X)     lm(.response ~ ., data = train_df, ...)   },   predict = function(object, newdata, ...) {     stats::predict(object, newdata = newdata, ...)   } ) m4 <- fit(value ~ p(12), data = retail,           date = \"date\", groups = \"items\", model = custom_model) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"Produce forecasts fitted tsfeature_fit model using recursive prediction. forecast step feeds back model lag feature subsequent steps.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"","code":"# S3 method for class 'tsfeature_fit' forecast(   object,   h = NULL,   future = NULL,   xreg_strategy = c(\"carry\", \"zeros\", \"NA\", \"error\"),   return_index = FALSE,   use_cpp = TRUE,   verbose = FALSE,   ... )"},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"object tsfeature_fit object created fit() h Integer, forecast horizon (number steps ahead). Required future NULL future Optional data frame containing future dates exogenous variables. Must include date column, group columns, raw exogenous variables used model xreg_strategy Strategy handling missing exogenous variables future NULL: \"carry\" - Carry forward last observed values \"zeros\" - Fill zeros \"NA\" - Fill NA \"error\" - Throw error exogenous variables needed return_index Logical, TRUE return forecast steps (1, 2, ..., h) instead dates use_cpp Logical, TRUE use C++ accelerated forecasting possible (default: TRUE) verbose Logical, TRUE print informational messages forecasting path used (default: FALSE) ... Additional arguments (currently unused, S3 method compatibility)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"Data frame columns: Group columns (specified fit) Date column step index {target}_forecast - Point forecasts","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"forecast process: group, compute features history Predict one step ahead Append prediction history Repeat h steps future provided, future dates generated based frequency stored model (TimeSeries object) using median time difference historical data within group (fallback).","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"edge-cases-during-forecasting","dir":"Reference","previous_headings":"","what":"Edge Cases During Forecasting","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"Incomplete Windows Rolling Statistics: recursive forecasting, requested window size exceeds available history (actual observations + previous predictions), rolling statistics moving averages return NA match training behavior. Example forecast step 3 rollsum(7): Available history: 3 predicted values Requested window: 7 Result: NA (incomplete window) ensures consistency training forecasting: Training uses slider::slide_dbl(..., .complete = TRUE) returns NA incomplete windows Forecasting mirrors returning NA length(history) < window Prevents train/test feature distribution mismatch Models see NA pattern training forecasting NA--incomplete behavior applies : rollsd(), rollmin(), rollmax(), rollslope(), moving averages. Unknown Factor Levels: future contains factor variables levels observed training (e.g., new category), values silently converted NA. can happen calendar features training data cover days/months, categorical exogenous variables. Trend Features: Trend features (trend(1), trend(2), etc.) continue incrementing beyond training range. example, trained 100 observations, forecast step 1 trend=101.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/forecast.tsfeature_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Recursive Multi-Step Forecasts — forecast.tsfeature_fit","text":"","code":"if (FALSE) { # \\dontrun{ # Fit a model m <- fit(value ~ p(12) + q(7, 28) + month(),          data = retail, date = \"date\", groups = \"items\", model = lm)  # Generate 24-step ahead forecast fc <- forecast(m, h = 24)  # Forecast with step index instead of dates fc <- forecast(m, h = 24, return_index = TRUE)  # Provide future exogenous variables future_data <- expand.grid(   date = seq(as.Date(\"2010-01-01\"), by = \"month\", length.out = 12),   items = unique(retail$items),   price = 9.99,   promotion = 0 ) fc <- forecast(m, future = future_data) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/print.TimeSeries.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for TimeSeries — print.TimeSeries","title":"Print method for TimeSeries — print.TimeSeries","text":"Print method TimeSeries","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/print.TimeSeries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for TimeSeries — print.TimeSeries","text":"","code":"# S3 method for class 'TimeSeries' print(x, ...)"},{"path":"https://taf-society.github.io/chronofeat/reference/print.TimeSeries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for TimeSeries — print.TimeSeries","text":"x TimeSeries object ... Additional arguments (unused)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/print.cv_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for cv_forecast — print.cv_forecast","title":"Print method for cv_forecast — print.cv_forecast","text":"Print method cv_forecast","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/print.cv_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for cv_forecast — print.cv_forecast","text":"","code":"# S3 method for class 'cv_forecast' print(x, ...)"},{"path":"https://taf-society.github.io/chronofeat/reference/print.cv_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for cv_forecast — print.cv_forecast","text":"x cv_forecast object ... Additional arguments (ignored)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics forecast","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/retail.html","id":null,"dir":"Reference","previous_headings":"","what":"Retail Sales Dataset — retail","title":"Retail Sales Dataset — retail","text":"sample retail sales time series dataset monthly observations multiple product categories. Useful demonstrating testing chronofeat package functions.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/retail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retail Sales Dataset — retail","text":"","code":"retail"},{"path":"https://taf-society.github.io/chronofeat/reference/retail.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Retail Sales Dataset — retail","text":"tibble 13,986 rows 3 columns: date Date observation (monthly, Date class) items Product category identifier (factor 42 levels) value Sales value (numeric)","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/retail.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Retail Sales Dataset — retail","text":"Synthetic retail sales data package examples testing.","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/retail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retail Sales Dataset — retail","text":"","code":"if (FALSE) { # \\dontrun{ # Load the data data(retail)  # Create a TimeSeries object ts <- TimeSeries(retail, date = \"date\", groups = \"items\", frequency = \"month\")  # Fit a model m <- fit(value ~ p(12) + month(), data = ts, model = lm)  # Generate forecasts fc <- forecast(m, h = 12) } # }"},{"path":"https://taf-society.github.io/chronofeat/reference/summary.cv_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for cv_forecast — summary.cv_forecast","title":"Summary method for cv_forecast — summary.cv_forecast","text":"Summary method cv_forecast","code":""},{"path":"https://taf-society.github.io/chronofeat/reference/summary.cv_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for cv_forecast — summary.cv_forecast","text":"","code":"# S3 method for class 'cv_forecast' summary(object, ...)"},{"path":"https://taf-society.github.io/chronofeat/reference/summary.cv_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for cv_forecast — summary.cv_forecast","text":"object cv_forecast object ... Additional arguments (ignored)","code":""},{"path":[]},{"path":"https://taf-society.github.io/chronofeat/news/index.html","id":"major-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"chronofeat 0.6.0","text":"Getting Started guide Building Custom Models (primary focus) Feature Engineering Reference Data Preprocessing Cross-Validation Advanced Workflows (including ParBayesianOptimization) .build_future_grid(): Unified future date generation grouped/ungrouped data .prepare_feature_row(): Centralized target/calendar/xreg feature assembly .apply_schema(): Centralized schema harmonization predictor selection Unified forecast loop: Replaced separate grouped/ungrouped branches single loop treating ungrouped pseudo-group","code":""},{"path":"https://taf-society.github.io/chronofeat/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"chronofeat 0.6.0","text":"Window Validation: C++ forecasting path now returns NA incomplete rolling/trend windows instead silently shortening , aligning R-side behavior preventing train/test feature distribution mismatch Cross-Validation: Added panel alignment validation detects reports misaligned date ranges across groups Grouped Features: Fixed grouped rolling/MA/lag features bleeding across group boundaries ensuring operations respect group_by() Trend Index: Corrected trend feature indexing recursive forecasting - now uses length(y) + 1 next step instead length(y) Factor Coercion: Now errors attempting rolling statistics factor columns instead silently converting meaningless numeric codes","code":""},{"path":"https://taf-society.github.io/chronofeat/news/index.html","id":"chronofeat-050","dir":"Changelog","previous_headings":"","what":"chronofeat 0.5.0","title":"chronofeat 0.5.0","text":"Initial release formula-based time series forecasting engine.","code":""},{"path":"https://taf-society.github.io/chronofeat/news/index.html","id":"features-0-5-0","dir":"Changelog","previous_headings":"","what":"Features","title":"chronofeat 0.5.0","text":"Formula interface feature specification: value ~ p(12) + q(7) + month() + dow() Target lags: p(k) creates k lags Moving averages: q(w1, w2, ...) creates MAs specified windows Calendar features: dow(), month(), woy(), eom(), dom() Rolling statistics: rollsum(), rollsd(), rollmin(), rollmax(), rollslope() Trend features: trend(1, 2, ...) polynomial trends Exogenous variable lags/MAs: lag(var, k), ma(var, w) Model-agnostic interface supporting R model fit/predict C++ accelerated recursive forecasting via Rcpp Multi-group/panel data support Time series cross-validation cv_forecast() TimeSeries object frequency detection preprocessing","code":""}]
